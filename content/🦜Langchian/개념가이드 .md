
이 섹션에는 LangChain의 주요 부분에 대한 소개가 포함되어 있습니다.

## 구조

프레임워크로서의 LangChain은 여러 패키지로 구성됩니다.
### langchain-core
이 패키지에는 다양한 구성 요소의 기본 추상화와 이를 함께 구성하는 방법이 포함되어 있습니다. LLM, 벡터 저장소, 리트리버 등과 같은 핵심 구성 요소에 대한 인터페이스가 여기에 정의되어 있습니다. 여기에는 타사 통합이 정의되어 있지 않습니다. 종속성은 의도적으로 매우 가볍게 유지됩니다.

### 파트너 패키지
인기 있는 통합은 자체 패키지(예: , , 등)로 분할합니다. 이는 이러한 중요한 통합에 대한 지원을 개선하기 위해 수행되었습니다.`langchain-community``langchain-openai``langchain-anthropic`

### langchain​
패키지에는 체인, 에이전트 및 검색 전략이 포함되어 있으며, 이들은 애플리케이션의 인지 아키텍처를 구성합니다. 이는 타사 통합이 아닙니다. 여기에 있는 모든 체인, 에이전트 및 검색 전략은 하나의 통합에만 국한되지 않고 모든 통합에서 일반적입니다.`langchain`

### langchain-community
이 패키지에는 LangChain 커뮤니티에서 유지 관리하는 타사 통합이 포함되어 있습니다. 주요 파트너 패키지는 분리되어 있습니다(아래 참조). 여기에는 다양한 구성 요소(LLM, 벡터 저장소, 리트리버)에 대한 모든 통합이 포함됩니다. 이 패키지의 모든 종속성은 패키지를 가능한 한 가볍게 유지하기 위해 선택 사항입니다.

### 랭그라프
`langgraph` 를 겨냥한 확장입니다. LLM으로 강력하고 스테이트풀(stateful) 멀티액터 애플리케이션을 구축하여 단계를 그래프의 에지와 노드로 모델링합니다.`langchain`

LangGraph는 일반적인 유형의 에이전트를 생성하기 위한 고수준 인터페이스와 사용자 지정 흐름을 구성하기 위한 저수준 API를 제공합니다.

### 랭서브
LangChain 체인을 REST API로 배포하기 위한 패키지입니다. 프로덕션 준비 API를 쉽게 시작하고 실행할 수 있습니다.

### 랭스미스

LLM 애플리케이션을 디버그, 테스트, 평가 및 모니터링할 수 있는 개발자 플랫폼입니다.

![Diagram outlining the hierarchical organization of the LangChain framework, displaying the interconnected parts across multiple layers.](https://python.langchain.com/v0.2/svg/langchain_stack_062024_dark.svg "LangChain Framework Overview")

## LangChain 표현 언어(LCEL)

LangChain 표현식 언어(LCEL)는 LangChain 구성 요소를 연결하는 선언적 방법입니다. LCEL은 가장 단순한 "프롬프트 + LLM" 체인에서 가장 복잡한 체인에 이르기까지 **코드 변경 없이 프로토타입을 프로덕션에 배치**할 수 있도록 1일차부터 설계되었습니다(우리는 사람들이 프로덕션에서 100개의 단계로 LCEL 체인을 성공적으로 실행하는 것을 보았습니다). LCEL을 사용해야 하는 몇 가지 이유를 강조하면 다음과 같습니다.

**최고 수준의 스트리밍 지원** LCEL로 체인을 구축하면 첫 번째 토큰까지의 시간(첫 번째 출력 청크가 나올 때까지 경과된 시간)을 최대한 활용할 수 있습니다. 일부 체인의 경우 이는 예를 들어 다음을 의미합니다. 우리는 LLM에서 스트리밍 출력 파서로 토큰을 직접 스트리밍하고, LLM 공급자가 원시 토큰을 출력하는 것과 동일한 속도로 구문 분석된 증분 출력 청크를 다시 가져옵니다.

**비동기 지원** LCEL로 구축된 모든 체인은 동기 API(예: 프로토타이핑 중 Jupyter 노트북에서)와 비동기 API(예: [LangServe](https://python.langchain.com/v0.2/docs/langserve/) 서버)를 사용하여 호출할 수 있습니다. 이를 통해 프로토타입 및 프로덕션에 동일한 코드를 사용하여 성능이 향상되고 동일한 서버에서 많은 동시 요청을 처리할 수 있습니다.

**최적화된 병렬 실행** LCEL 체인에 병렬로 실행할 수 있는 단계가 있을 때마다(예: 여러 리트리버에서 문서를 가져오는 경우) 가능한 한 가장 짧은 대기 시간을 위해 동기화 및 비동기 인터페이스 모두에서 자동으로 실행합니다.

**재시도 및 대체** LCEL 체인의 모든 부분에 대한 재시도 및 폴백을 구성합니다. 이것은 체인을 대규모로 보다 안정적으로 만들 수 있는 좋은 방법입니다. 현재 재시도/대체에 대한 스트리밍 지원을 추가하는 작업을 진행 중이므로 대기 시간 비용 없이 안정성을 높일 수 있습니다.

**중간 결과 액세스** 더 복잡한 체인의 경우 최종 출력이 생성되기 전에도 중간 단계의 결과에 액세스하는 것이 매우 유용한 경우가 많습니다. 이는 최종 사용자에게 어떤 일이 일어나고 있음을 알리거나 체인을 디버그하는 데 사용할 수 있습니다. 중간 결과를 스트리밍할 수 있으며 모든 [LangServe](https://python.langchain.com/v0.2/docs/langserve/) 서버에서 사용할 수 있습니다.

**입력 및 출력 스키마Input and output schemas** 입력 및 출력 스키마는 체인의 구조에서 유추된 모든 LCEL 체인 Pydantic 및 JSONSchema 스키마를 제공합니다. 이것은 입력 및 출력의 유효성 검사에 사용할 수 있으며 LangServe의 필수적인 부분입니다.

[**원활한 LangSmith 추적**](https://docs.smith.langchain.com/) 체인이 점점 더 복잡해짐에 따라 모든 단계에서 정확히 무슨 일이 일어나고 있는지 이해하는 것이 점점 더 중요해지고 있습니다. LCEL을 사용하면 **모든** 단계가 [LangSmith](https://docs.smith.langchain.com/)에 자동으로 기록되어 관찰 가능성과 디버깅 가능성을 극대화합니다.

LCEL은 및 와 같은 레거시 서브클래싱된 체인에 대한 동작 및 사용자 정의에 대한 일관성을 제공하는 것을 목표로 합니다. 이러한 레거시 체인 중 다수는 프롬프트와 같은 중요한 세부 정보를 숨기고 있으며 더 다양합니다 실행 가능한 모델이 등장함에 따라 사용자 정의가 점점 더 중요해지고 있습니다.`LLMChain``ConversationalRetrievalChain`

현재 이러한 레거시 체인 중 하나를 사용하고 있는 경우 [이 가이드를 참조하여 마이그레이션 방법에 대한 지침을](https://python.langchain.com/v0.2/docs/versions/migrating_chains/) 확인하세요.

LCEL을 사용하여 특정 작업을 수행하는 방법에 대한 지침은 [관련 방법 가이드를](https://python.langchain.com/v0.2/docs/how_to/#langchain-expression-language-lcel) 확인하세요.

### 실행 가능한 인터페이스 ( Runnable interface )

사용자 정의 체인을 가능한 한 쉽게 만들 수 있도록 ["Runnable"](https://api.python.langchain.com/en/stable/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable) 프로토콜을 구현했습니다. 많은 LangChain 구성 요소는 채팅 모델, LLM, 출력 파서, 리트리버, 프롬프트 템플릿 등을 포함하여 프로토콜을 구현합니다. runnables 작업에 유용한 프리미티브도 몇 가지 있으며, 이에 대해서는 아래에서 확인할 수 있습니다.`Runnable`

이것은 표준 인터페이스로, 사용자 정의 체인을 쉽게 정의하고 표준 방식으로 호출할 수 있습니다. 표준 인터페이스에는 다음이 포함됩니다.
- `stream`: 응답의 청크를 다시 스트림합니다.
- `invoke`: 입력에서 체인을 호출합니다.
- `batch`: 입력 목록에서 체인을 호출합니다.

이것들은 또한 동시성을 위해 [asyncio](https://docs.python.org/3/library/asyncio.html) `await`구문과 함께 사용해야 하는 해당 비동기 메서드가 있습니다:
- `astream`: 응답 async의 청크를 다시 스트리밍합니다.
- `ainvoke`: 입력 비동기에서 체인을 호출합니다.
- `abatch`: 입력 목록에서 체인을 비동기로 호출합니다.
- `astream_log`: 최종 응답과 함께 중간 단계가 발생할 때 다시 스트리밍합니다.
- `astream_events`: 체인에서 발생하는 베**타** 스트림 이벤트 (0.1.14에 도입)`langchain-core`

**입력 유형**과 **출력 유형은** 구성 요소에 따라 다릅니다.

| 구성 요소                | 입력 유형                            | 출력 유형     |
| -------------------- | -------------------------------- | --------- |
| Prompt               | 사전                               | 프롬프트값     |
| ChatModel            | 단일 문자열, 채팅 메시지 목록 또는 PromptValue | 채팅메시지     |
| LLM                  | 단일 문자열, 채팅 메시지 목록 또는 PromptValue | 문자열       |
| OutputParser (출력 파서) | LLM 또는 ChatModel의 출력             | 파서에 따라 다름 |
| Retriever            | 단일 문자열                           | 문서 목록     |
| Tool                 | 단일 문자열 또는 딕셔너리(도구에 따라 다름)        | 도구에 따라 다름 |

모든 runnables는 input 및 output **스키마를** 노출하여 input과 outputs를 검사합니다.
- `input_schema`: Runnable의 구조에서 자동 생성 된 입력 Pydantic 모델
- `output_schema`: Runnable의 구조에서 자동 생성 된 출력 Pydantic 모델

## 구성 요소[](https://python.langchain.com/v0.2/docs/concepts/#components "Direct link to Components")

LangChain은 LLM으로 빌드하는 데 유용한 다양한 구성 요소에 대한 확장 가능한 표준 인터페이스 및 외부 통합을 제공합니다. LangChain이 구현하는 일부 구성 요소, 타사 통합에 의존하는 일부 구성 요소 및 다른 구성 요소는 혼합되어 있습니다.

### 채팅 모델[](https://python.langchain.com/v0.2/docs/concepts/#chat-models "Direct link to Chat models")

메시지 시퀀스를 입력으로 사용하고 채팅 메시지를 출력으로 반환하는 언어 모델(일반 텍스트를 사용하는 것과 반대). 이들은 전통적으로 최신 모델입니다(이전 모델은 일반적으로 아래 참조). 채팅 모델은 대화 메시지에 고유한 역할을 할당할 수 있도록 지원하여 AI, 사용자 및 시스템 메시지와 같은 지침과 메시지를 구별하는 데 도움이 됩니다.`LLMs`

기본 모델은 메시지 입력, 메시지 출력이지만 LangChain 래퍼를 사용하면 이러한 모델도 문자열을 입력으로 사용할 수 있습니다. 즉, LLM 대신 채팅 모델을 쉽게 사용할 수 있습니다.

문자열이 입력으로 전달되면 a로 변환된 다음 기본 모델로 전달됩니다.`HumanMessage`

LangChain은 채팅 모델을 호스팅하지 않으며 대신 타사 통합에 의존합니다.

ChatModel을 구성할 때 몇 가지 표준화된 매개변수가 있습니다.

- `model`: 모델의 이름
- `temperature`: 샘플링 온도
- `timeout`: 요청 시간 초과
- `max_tokens`: 생성할 최대 토큰 수
- `stop`: 기본 정지 시퀀스
- `max_retries`: 요청을 재시도할 수 있는 최대 횟수
- `api_key`: 모델 공급자의 API 키
- `base_url`: 요청을 보낼 엔드포인트

유의해야 할 몇 가지 중요한 사항은 다음과 같습니다.

- 표준 매개 변수는 의도한 기능으로 매개 변수를 노출하는 모델 공급자에만 적용됩니다. 예를 들어 일부 공급자는 최대 출력 토큰에 대한 구성을 노출하지 않으므로 이러한 공급자max_tokens 지원할 수 없습니다.
- 표준 매개변수는 현재 자체 통합 패키지(예: , 등)가 있는 통합에만 적용되며 의 모델에는 적용되지 않습니다.`langchain-openai``langchain-anthropic``langchain-community`

ChatModel은 해당 통합과 관련된 다른 매개 변수도 허용합니다. ChatModel에서 지원하는 모든 매개 변수를 찾으려면 해당 모델에 대한 API 참조로 이동합니다.

정보

일부 채팅 모델은 **도구 호출**을 위해 미세 조정되었으며 이를 위한 전용 API를 제공합니다. 일반적으로 이러한 모델은 미세 조정되지 않은 모델보다 도구 호출이 더 우수하며 도구 호출이 필요한 사용 사례에 권장됩니다. 자세한 내용은 [도구 호출 섹션을](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling) 참조하십시오.

채팅 모델을 사용하는 방법에 대한 자세한 내용은 [여기에서 관련 방법 가이드를](https://python.langchain.com/v0.2/docs/how_to/#chat-models) 참조하세요.

#### 멀티모달리티(Multimodality)[](https://python.langchain.com/v0.2/docs/concepts/#multimodality "Direct link to Multimodality")

일부 채팅 모델은 이미지, 오디오 및 비디오를 입력으로 받아들이는 멀티모달입니다. 이는 여전히 덜 일반적이며, 이는 모델 제공자가 API를 정의하는 "최상의" 방법을 표준화하지 않았다는 것을 의미합니다. 멀티모달 **출력**은 훨씬 더 흔하지 않습니다. 따라서 우리는 멀티모달 추상화를 상당히 가볍게 유지했으며 이 분야가 성숙해짐에 따라 멀티모달 API와 상호 작용 패턴을 더욱 공고히 할 계획입니다.

LangChain에서 멀티모달 입력을 지원하는 대부분의 채팅 모델은 OpenAI의 콘텐츠 블록 형식에서도 해당 값을 허용합니다. 지금까지는 이미지 입력으로 제한되었습니다. 비디오 및 기타 바이트 입력을 지원하는 Gemini와 같은 모델의 경우 API는 기본 모델별 표현도 지원합니다.

다중 모드 모델을 사용하는 방법에 대한 자세한 내용은 [여기에서 관련 방법 가이드를](https://python.langchain.com/v0.2/docs/how_to/#multimodal) 참조하세요.

멀티모달 모델을 사용하는 LangChain 모델 공급자의 전체 목록은 [이 표를 확인하세요](https://python.langchain.com/v0.2/docs/integrations/chat/#advanced-features).

### 법학석사([](https://python.langchain.com/v0.2/docs/concepts/#llms "Direct link to LLMs")LLM)

주의

순수 텍스트 입력/텍스트 출력 LLM은 더 오래되거나 낮은 수준인 경향이 있습니다. 많은 인기 모델이 [채팅 완성 모델](https://python.langchain.com/v0.2/docs/concepts/#chat-models)로 가장 잘 사용됩니다. 채팅이 아닌 사용 사례의 경우에도 마찬가지입니다.

[대신 위의 섹션을](https://python.langchain.com/v0.2/docs/concepts/#chat-models) 찾고 있을 것입니다.

문자열을 입력으로 사용하고 문자열을 반환하는 언어 모델입니다. 이들은 전통적으로 오래된 모델입니다(최신 모델은 일반적으로 [채팅 모델](https://python.langchain.com/v0.2/docs/concepts/#chat-models)입니다. 위 참조).

기본 모델은 string in, string out이지만 LangChain 래퍼를 사용하면 이러한 모델도 메시지를 입력으로 사용할 수 있습니다. [이렇게 하면 채팅 모델](https://python.langchain.com/v0.2/docs/concepts/#chat-models)과 동일한 인터페이스가 제공됩니다. 메시지가 입력으로 전달되면 기본 모델에 전달되기 전에 내부적으로 문자열로 형식이 지정됩니다.

LangChain은 LLM을 호스팅하지 않으며 대신 타사 통합에 의존합니다.

LLM 사용 방법에 대한 자세한 내용은 [여기에서 관련 사용 방법 가이드를](https://python.langchain.com/v0.2/docs/how_to/#llms) 참조하세요.

### 메시지[](https://python.langchain.com/v0.2/docs/concepts/#messages "Direct link to Messages")

일부 언어 모델은 메시지 목록을 입력으로 사용하고 메시지를 반환합니다. 메시지에는 몇 가지 다른 유형이 있습니다. 모든 메시지에는 , 및 속성이 있습니다.`role``content``response_metadata`

WHO가 메시지를 말하고 있다고 설명합니다. LangChain에는 역할마다 다른 메시지 클래스가 있습니다.`role`

이 속성은 메시지의 내용을 설명합니다. 이것은 몇 가지 다른 것일 수 있습니다.`content`

- 문자열(대부분의 모델은 이러한 유형의 콘텐츠를 처리함)
- 딕셔너리 목록(멀티모달 입력에 사용되며, 딕셔너리에는 해당 입력 유형과 해당 입력 위치에 대한 정보가 포함됨)

#### 휴먼메시지[](https://python.langchain.com/v0.2/docs/concepts/#humanmessage "Direct link to HumanMessage")

이는 사용자의 메시지를 나타냅니다.

#### AI메사지[](https://python.langchain.com/v0.2/docs/concepts/#aimessage "Direct link to AIMessage")

이는 모델의 메시지를 나타냅니다. 속성 외에도 이러한 메시지에는 다음이 포함됩니다.`content`

**`response_metadata`**

이 속성에는 응답에 대한 추가 메타데이터가 포함되어 있습니다. 여기에 있는 데이터는 각 모델 공급자에 따라 관련이 있는 경우가 많습니다. 여기에서 log-probs 및 토큰 사용과 같은 정보가 저장될 수 있습니다.`response_metadata`

**`tool_calls`**

이는 도구를 호출하기 위한 언어 모델의 결정을 나타냅니다. 출력의 일부로 포함됩니다. 그들은 재산과 함께 거기에서 접근 할 수 있습니다.`AIMessage``.tool_calls`

이 속성은 s의 목록을 반환합니다. A는 다음과 같은 인자를 갖는 딕셔너리입니다.`ToolCall``ToolCall`

- `name`: 호출해야 하는 도구의 이름입니다.
- `args`: 해당 도구에 대한 인수입니다.
- `id`: 해당 도구 호출의 ID입니다.

#### 시스템 메시지[](https://python.langchain.com/v0.2/docs/concepts/#systemmessage "Direct link to SystemMessage")

이는 모델이 어떻게 동작해야 하는지 알려주는 시스템 메시지를 나타냅니다. 모든 모델 공급자가 이를 지원하는 것은 아닙니다.

#### 툴메시지[](https://python.langchain.com/v0.2/docs/concepts/#toolmessage "Direct link to ToolMessage")

이는 도구 호출의 결과를 나타냅니다. 및 외에도 이 메시지에는 다음이 있습니다.`role``content`

- 이 결과를 생성하기 위해 호출된 도구에 대한 호출의 ID를 전달하는 필드입니다.`tool_call_id`
- 추적에 유용하지만 모델로 전송해서는 안 되는 도구 실행의 임의의 아티팩트를 전달하는 데 사용할 수 있는 필드입니다.`artifact`

#### (레거시) 함수메시지[](https://python.langchain.com/v0.2/docs/concepts/#legacy-functionmessage "Direct link to (Legacy) FunctionMessage")

OpenAI의 레거시 함수 호출 API에 해당하는 레거시 메시지 유형입니다. 업데이트된 도구 호출 API에 해당하는 데 대신 사용해야 합니다.`ToolMessage`

이는 함수 호출의 결과를 나타냅니다. 및 외에도 이 메시지에는 이 결과를 생성하기 위해 호출된 함수의 이름을 전달하는 매개변수가 있습니다.`role``content``name`

### 프롬프트 템플릿[](https://python.langchain.com/v0.2/docs/concepts/#prompt-templates "Direct link to Prompt templates")

프롬프트 템플릿은 사용자 입력 및 매개 변수를 언어 모델에 대한 지침으로 변환하는 데 도움이 됩니다. 이는 모델의 응답을 안내하는 데 사용할 수 있으며, 컨텍스트를 이해하고 관련성 있고 일관된 언어 기반 출력을 생성하는 데 도움이 됩니다.

프롬프트 템플릿은 딕셔너리를 입력으로 사용하며, 각 키는 채울 프롬프트 템플릿의 변수를 나타냅니다.

프롬프트 템플릿은 PromptValue를 출력합니다. 이 PromptValue 는 LLM 또는 ChatModel 에 전달될 수 있으며, 문자열 또는 메시지 목록으로 캐스트될 수도 있습니다. 이 PromptValue가 존재하는 이유는 문자열과 메시지 간에 쉽게 전환할 수 있도록 하기 위해서입니다.

다음과 같은 몇 가지 유형의 프롬프트 템플릿이 있습니다.

#### 문자열 PromptTemplates[](https://python.langchain.com/v0.2/docs/concepts/#string-prompttemplates "Direct link to String PromptTemplates")

이러한 프롬프트 템플릿은 단일 문자열의 형식을 지정하는 데 사용되며 일반적으로 더 간단한 입력에 사용됩니다. 예를 들어 PromptTemplate을 생성하고 사용하는 일반적인 방법은 다음과 같습니다.

```
from langchain_core.prompts import PromptTemplateprompt_template = PromptTemplate.from_template("Tell me a joke about {topic}")prompt_template.invoke({"topic": "cats"})
```

**API 참조:**[PromptTemplate](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.prompt.PromptTemplate.html)

#### ChatPrompt템플릿[](https://python.langchain.com/v0.2/docs/concepts/#chatprompttemplates "Direct link to ChatPromptTemplates")

이러한 프롬프트 템플릿은 메시지 목록의 서식을 지정하는 데 사용됩니다. 이러한 "템플릿"은 템플릿 자체의 목록으로 구성됩니다. 예를 들어 ChatPromptTemplate을 생성하고 사용하는 일반적인 방법은 다음과 같습니다.

```
from langchain_core.prompts import ChatPromptTemplateprompt_template = ChatPromptTemplate.from_messages([    ("system", "You are a helpful assistant"),    ("user", "Tell me a joke about {topic}")])prompt_template.invoke({"topic": "cats"})
```

**API 참조:**[ChatPromptTemplate](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)

위의 예에서 이 ChatPromptTemplate은 호출될 때 두 개의 메시지를 생성합니다. 첫 번째는 형식화할 변수가 없는 시스템 메시지입니다. 두 번째는 HumanMessage이며 사용자가 전달하는 변수에 의해 형식이 지정됩니다.`topic`

#### 메시지플레이스홀더[](https://python.langchain.com/v0.2/docs/concepts/#messagesplaceholder "Direct link to MessagesPlaceholder")

이 프롬프트 템플릿은 특정 위치에 메시지 목록을 추가하는 역할을 합니다. 위의 ChatPromptTemplate에서 각각 문자열인 두 개의 메시지를 형식화하는 방법을 보았습니다. 그러나 사용자가 특정 위치에 끼워 넣을 메시지 목록을 전달하려면 어떻게 될까요? 이것이 MessagesPlaceholder를 사용하는 방법입니다.

```
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholderfrom langchain_core.messages import HumanMessageprompt_template = ChatPromptTemplate.from_messages([    ("system", "You are a helpful assistant"),    MessagesPlaceholder("msgs")])prompt_template.invoke({"msgs": [HumanMessage(content="hi!")]})
```

**API 참조:**[ChatPromptTemplate](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html) | [메시지플레이스홀더](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.MessagesPlaceholder.html) | [휴먼메시지](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.human.HumanMessage.html)

이렇게 하면 두 개의 메시지 목록이 생성되는데, 첫 번째는 시스템 메시지이고 두 번째는 전달한 HumanMessage입니다. 5개의 메시지를 전달했다면 총 6개의 메시지(시스템 메시지와 전달된 5개)가 생성되었을 것입니다. 이 기능은 메시지 목록을 특정 위치에 배치하는 데 유용합니다.

클래스를 명시 적으로 사용하지 않고 동일한 작업을 수행하는 다른 방법은 다음과 같습니다.`MessagesPlaceholder`

```
prompt_template = ChatPromptTemplate.from_messages([    ("system", "You are a helpful assistant"),    ("placeholder", "{msgs}") # <-- This is the changed part])
```

프롬프트 템플릿을 사용하는 방법에 대한 자세한 내용은 [여기에서 관련 방법 가이드를](https://python.langchain.com/v0.2/docs/how_to/#prompt-templates) 참조하세요.

### 선택기 예시[](https://python.langchain.com/v0.2/docs/concepts/#example-selectors "Direct link to Example selectors")

더 나은 성능을 얻기 위한 일반적인 프롬프트 기술 중 하나는 프롬프트의 일부로 예제를 포함하는 것입니다. 이것은 언어 모델이 어떻게 작동해야 하는지에 대한 구체적인 예를 제공합니다. 때때로 이러한 예제는 프롬프트에 하드 코딩되지만 고급 상황에서는 동적으로 선택하는 것이 좋을 수 있습니다. Example Selectors는 예제를 선택하고 프롬프트로 형식을 지정하는 클래스입니다.

예제 선택기를 사용하는 방법에 대한 자세한 내용은 [여기에서 관련 방법 가이드를](https://python.langchain.com/v0.2/docs/how_to/#example-selectors) 참조하세요.

### 출력 구문 분석기[](https://python.langchain.com/v0.2/docs/concepts/#output-parsers "Direct link to Output parsers")

메모

여기서 정보는 모델에서 텍스트 출력을 가져와서 보다 구조화된 표현으로 구문 분석하려고 시도하는 파서를 나타냅니다. 점점 더 많은 모델이 이를 자동으로 처리하는 함수(또는 도구) 호출을 지원하고 있습니다. 출력 구문 분석보다는 함수/도구 호출을 사용하는 것이 좋습니다. 이에 대한 설명서[는 여기를](https://python.langchain.com/v0.2/docs/concepts/#function-tool-calling) 참조하십시오.

모델의 출력을 가져와서 다운스트림 작업에 더 적합한 형식으로 변환하는 일을 담당합니다. LLM을 사용하여 구조화된 데이터를 생성하거나 채팅 모델 및 LLM의 출력을 정규화할 때 유용합니다.

LangChain에는 다양한 유형의 출력 파서가 있습니다. LangChain이 지원하는 출력 파서 목록입니다. 아래 표에는 다양한 정보가 있습니다.

**이름**: 출력 파서의 이름

**스트리밍 지원**: 출력 파서가 스트리밍을 지원하는지 여부입니다.

**Has Format Instructions**: 출력 구문 분석기에 형식 명령어가 있는지 여부입니다. 이것은 (a) 원하는 스키마가 프롬프트에 지정되지 않고 다른 매개변수(예: OpenAI 함수 호출)에 지정되거나 (b) OutputParser가 다른 OutputParser를 래핑하는 경우를 제외하고 일반적으로 사용할 수 있습니다.

**Calls LLM**: 이 출력 파서 자체가 LLM을 호출하는지 여부. 이것은 일반적으로 잘못 형식화 된 출력을 수정하려고 시도하는 출력 구문 분석기에 의해서만 수행됩니다.

**입력 유형**: 예상 입력 유형입니다. 대부분의 출력 파서는 문자열과 메시지 모두에서 작동하지만 일부(예: OpenAI Functions)에는 특정 kwargs가 있는 메시지가 필요합니다.

**Output Type**: 파서에서 반환된 객체의 출력 유형입니다.

**설명**: 이 출력 파서에 대한 설명과 사용 시기.

|이름|스트리밍 지원|형식 지시어가 있습니다.|LLM을 호출합니다.|입력 유형|출력 유형|묘사|
|---|---|---|---|---|---|---|
|[JSON (영문)](https://api.python.langchain.com/en/latest/output_parsers/langchain_core.output_parsers.json.JsonOutputParser.html#langchain_core.output_parsers.json.JsonOutputParser)|✅|✅||`str` \| `Message`|JSON 객체|지정된 대로 JSON 개체를 반환합니다. Pydantic 모델을 지정할 수 있으며 해당 모델에 대한 JSON을 반환합니다. 아마도 함수 호출을 사용하지 않는 구조화 된 데이터를 가져 오기위한 가장 신뢰할 수있는 출력 파서 일 것입니다.|
|[XML (영문)](https://api.python.langchain.com/en/latest/output_parsers/langchain_core.output_parsers.xml.XMLOutputParser.html#langchain_core.output_parsers.xml.XMLOutputParser)|✅|✅||`str` \| `Message`|`dict`|태그의 딕셔너리를 반환합니다. XML 출력이 필요한 경우 사용합니다. XML 작성에 능숙한 모델(예: Anthropic)과 함께 사용하십시오.|
|[증권 시세 표시기](https://api.python.langchain.com/en/latest/output_parsers/langchain_core.output_parsers.list.CommaSeparatedListOutputParser.html#langchain_core.output_parsers.list.CommaSeparatedListOutputParser)|✅|✅||`str` \| `Message`|`List[str]`|쉼표로 구분된 값 목록을 반환합니다.|
|[출력 고정](https://api.python.langchain.com/en/latest/output_parsers/langchain.output_parsers.fix.OutputFixingParser.html#langchain.output_parsers.fix.OutputFixingParser)|||✅|`str` \| `Message`||다른 출력 파서를 래핑합니다. 해당 출력 파서 오류가 발생하면 오류 메시지와 잘못된 출력을 LLM에 전달하고 출력을 수정하도록 요청합니다.|
|[RetryWithError (오류로 재시도)](https://api.python.langchain.com/en/latest/output_parsers/langchain.output_parsers.retry.RetryWithErrorOutputParser.html#langchain.output_parsers.retry.RetryWithErrorOutputParser)|||✅|`str` \| `Message`||다른 출력 파서를 래핑합니다. 해당 출력 파서에 오류가 발생하면 원래 입력, 잘못된 출력 및 오류 메시지를 LLM에 전달하고 수정을 요청합니다. OutputFixingParser와 비교할 때 이것은 원래 명령어도 보냅니다.|
|[피단틱](https://api.python.langchain.com/en/latest/output_parsers/langchain_core.output_parsers.pydantic.PydanticOutputParser.html#langchain_core.output_parsers.pydantic.PydanticOutputParser)||✅||`str` \| `Message`|`pydantic.BaseModel`|사용자 정의 Pydantic 모델을 사용하여 해당 형식으로 데이터를 반환합니다.|
|[떱댐](https://api.python.langchain.com/en/latest/output_parsers/langchain.output_parsers.yaml.YamlOutputParser.html#langchain.output_parsers.yaml.YamlOutputParser)||✅||`str` \| `Message`|`pydantic.BaseModel`|사용자 정의 Pydantic 모델을 사용하여 해당 형식으로 데이터를 반환합니다. YAML을 사용하여 인코딩합니다.|
|[판다스데이터프레임](https://api.python.langchain.com/en/latest/output_parsers/langchain.output_parsers.pandas_dataframe.PandasDataFrameOutputParser.html#langchain.output_parsers.pandas_dataframe.PandasDataFrameOutputParser)||✅||`str` \| `Message`|`dict`|pandas DataFrames로 작업을 수행하는 데 유용합니다.|
|[열거형](https://api.python.langchain.com/en/latest/output_parsers/langchain.output_parsers.enum.EnumOutputParser.html#langchain.output_parsers.enum.EnumOutputParser)||✅||`str` \| `Message`|`Enum`|response를 제공된 enum 값 중 하나로 구문 분석합니다.|
|[날짜/시간](https://api.python.langchain.com/en/latest/output_parsers/langchain.output_parsers.datetime.DatetimeOutputParser.html#langchain.output_parsers.datetime.DatetimeOutputParser)||✅||`str` \| `Message`|`datetime.datetime`|응답을 datetime 문자열로 구문 분석합니다.|
|[구조화 된](https://api.python.langchain.com/en/latest/output_parsers/langchain.output_parsers.structured.StructuredOutputParser.html#langchain.output_parsers.structured.StructuredOutputParser)||✅||`str` \| `Message`|`Dict[str, str]`|구조화된 정보를 반환하는 출력 파서입니다. 다른 출력 구문 분석기보다 덜 강력한데, 필드가 문자열만 허용하기 때문입니다. 이는 더 작은 LLM으로 작업할 때 유용할 수 있습니다.|

출력 파서를 사용하는 방법에 대한 자세한 내용은 [여기에서 관련 방법 가이드를](https://python.langchain.com/v0.2/docs/how_to/#output-parsers) 참조하세요.

### 채팅 기록[](https://python.langchain.com/v0.2/docs/concepts/#chat-history "Direct link to Chat history")

대부분의 LLM 애플리케이션에는 대화형 인터페이스가 있습니다. 대화의 필수 구성 요소는 대화 초반에 소개된 정보를 참조할 수 있는 것입니다. 최소한 대화형 시스템은 과거 메시지의 일부 창에 직접 액세스할 수 있어야 합니다.

의 개념은 임의의 체인을 래핑하는 데 사용할 수 있는 LangChain의 클래스를 나타냅니다. 이렇게 하면 기본 체인의 입력과 출력을 추적하고 메시지 데이터베이스에 메시지로 추가됩니다. 그런 다음 향후 상호 작용은 해당 메시지를 로드하고 입력의 일부로 체인에 전달합니다.`ChatHistory``ChatHistory`

### 문서[](https://python.langchain.com/v0.2/docs/concepts/#documents "Direct link to Documents")

LangChain의 Document 객체에는 일부 데이터에 대한 정보가 포함되어 있습니다. 여기에는 두 가지 속성이 있습니다.

- `page_content: str`: 이 문서의 내용입니다. 현재는 문자열일 뿐입니다.
- `metadata: dict`: 이 문서와 연결된 임의의 메타데이터입니다. 문서 ID, 파일 이름 등을 추적할 수 있습니다.

### 문서 로더[](https://python.langchain.com/v0.2/docs/concepts/#document-loaders "Direct link to Document loaders")

이러한 클래스는 Document 객체를 로드합니다. LangChain은 Slack, Notion, Google Drive 등 데이터를 로드할 수 있는 다양한 데이터 소스와 수백 개의 통합을 제공합니다.

각 DocumentLoader에는 고유한 특정 매개 변수가 있지만 모두 메서드를 사용하여 동일한 방식으로 호출할 수 있습니다. 사용 사례의 예는 다음과 같습니다.`.load`

```
from langchain_community.document_loaders.csv_loader import CSVLoaderloader = CSVLoader(    ...  # <-- Integration specific parameters here)data = loader.load()
```

**API 참조:**[CSVLoader](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.csv_loader.CSVLoader.html)

문서 로더 사용 방법에 대한 자세한 내용은 [여기에서 관련 방법 가이드를](https://python.langchain.com/v0.2/docs/how_to/#document-loaders) 참조하세요.

### 텍스트 분할자[](https://python.langchain.com/v0.2/docs/concepts/#text-splitters "Direct link to Text splitters")

문서를 로드한 후에는 응용 프로그램에 더 잘 맞도록 문서를 변환하고 싶을 때가 많습니다. 가장 간단한 예는 긴 문서를 모델의 컨텍스트 창에 들어갈 수 있는 더 작은 덩어리로 분할할 수 있다는 것입니다. LangChain에는 문서를 쉽게 분할, 결합, 필터링 및 조작할 수 있는 여러 가지 내장 문서 변환기가 있습니다.

긴 텍스트 조각을 처리하려면 해당 텍스트를 청크로 분할해야 합니다. 간단하게 들릴지 모르지만, 여기에는 많은 잠재적인 복잡성이 있습니다. 이상적으로는 의미상 관련된 텍스트 조각을 함께 유지하려고 합니다. "의미상 관련된"의 의미는 텍스트 유형에 따라 달라질 수 있습니다. 이 노트북은 이를 수행하는 몇 가지 방법을 보여줍니다.

높은 수준에서 텍스트 분할자는 다음과 같이 작동합니다.

1. 텍스트를 의미상 의미 있는 작은 덩어리(종종 문장)로 나눕니다.
2. 특정 크기에 도달할 때까지 이 작은 덩어리를 더 큰 덩어리로 결합하기 시작합니다(일부 함수로 측정됨).
3. 그 크기에 도달하면 해당 청크를 자체 텍스트 조각으로 만든 다음 일부 겹치는 새 텍스트 청크를 만들기 시작합니다(청크 간의 컨텍스트를 유지하기 위해).

즉, 텍스트 스플리터를 사용자 지정할 수 있는 두 개의 다른 축이 있습니다.

1. 텍스트 분할 방법
2. 청크 크기 측정 방법

텍스트 분할자를 사용하는 방법에 대한 자세한 내용은 [여기에서 관련 방법 가이드를](https://python.langchain.com/v0.2/docs/how_to/#text-splitters) 참조하세요.

### 모델[](https://python.langchain.com/v0.2/docs/concepts/#embedding-models "Direct link to Embedding models") 임베딩

임베딩 모델은 텍스트 조각의 벡터 표현을 만듭니다. 벡터는 텍스트의 의미론적 의미를 포착하는 숫자의 배열로 생각할 수 있습니다. 이러한 방식으로 텍스트를 표현하면 의미가 가장 유사한 다른 텍스트 조각을 검색하는 등의 작업을 수행할 수 있는 수학적 연산을 수행할 수 있습니다. 이러한 자연어 검색 기능은 다양한 유형의 [컨텍스트 검색을 뒷받침합니다](https://python.langchain.com/v0.2/docs/concepts/#retrieval). 여기서 LLM은 쿼리에 효과적으로 응답하는 데 필요한 관련 데이터를 제공합니다.

![](https://python.langchain.com/v0.2/assets/images/embeddings-9c2616450a3b4f497a2d95a696b5f1a7.png)

이 클래스는 텍스트 임베딩 모델과 인터페이스하도록 설계된 클래스입니다. 다양한 임베딩 모델 제공자(OpenAI, Cohere, Hugging Face 등)와 로컬 모델이 있으며, 이 클래스는 모든 제공자에게 표준 인터페이스를 제공하도록 설계되었습니다.`Embeddings`

LangChain의 기본 Embeddings 클래스는 문서를 포함하기 위한 방법과 쿼리를 포함하기 위한 방법의 두 가지 방법을 제공합니다. 전자는 여러 텍스트를 입력으로 사용하고 후자는 단일 텍스트를 사용합니다. 이를 두 개의 별도 방법으로 사용하는 이유는 일부 임베딩 제공 업체가 문서 (검색 할 것)와 쿼리 (검색 쿼리 자체)에 대해 다른 임베딩 방법을 가지고 있기 때문입니다.

임베딩 모델을 사용하는 방법에 대한 자세한 내용은 [여기에서 관련 방법 가이드를](https://python.langchain.com/v0.2/docs/how_to/#embedding-models) 참조하세요.

### 벡터 스토어[](https://python.langchain.com/v0.2/docs/concepts/#vector-stores "Direct link to Vector stores")

비정형 데이터를 저장하고 검색하는 가장 일반적인 방법 중 하나는 데이터를 임베드하고 결과 임베딩 벡터를 저장하는 것입니다. 그런 다음 쿼리 시간에 비정형 쿼리를 포함하고 포함된 쿼리와 '가장 유사한' 임베딩 벡터를 검색합니다. 벡터 저장소는 포함된 데이터를 저장하고 벡터 검색을 수행합니다.

대부분의 벡터 저장소는 포함된 벡터에 대한 메타데이터를 저장하고 이전에 해당 메타데이터에 대한 필터링을 지원할 수도 있습니다 유사성 검색을 통해 반환된 문서를 더 잘 제어할 수 있습니다.

벡터 저장소는 다음을 수행하여 retriever 인터페이스로 변환할 수 있습니다.

```
vectorstore = MyVectorStore()retriever = vectorstore.as_retriever()
```

벡터 스토어를 사용하는 방법에 대한 자세한 내용은 [여기에서 관련 방법 가이드를](https://python.langchain.com/v0.2/docs/how_to/#vector-stores) 참조하세요.

### 리트리버[](https://python.langchain.com/v0.2/docs/concepts/#retrievers "Direct link to Retrievers")

검색기는 구조화되지 않은 쿼리가 주어진 문서를 반환하는 인터페이스입니다. 벡터 저장소보다 더 일반적입니다. 검색기는 문서를 저장할 수 있을 필요가 없으며 문서를 반환(또는 검색)하기만 하면 됩니다. 리트리버는 벡터 스토어에서 만들 수 있지만 [Wikipedia 검색](https://python.langchain.com/v0.2/docs/integrations/retrievers/wikipedia/) 및 [Amazon Kendra](https://python.langchain.com/v0.2/docs/integrations/retrievers/amazon_kendra_retriever/)를 포함할 수 있을 만큼 충분히 광범위합니다.

리트리버는 문자열 쿼리를 입력으로 받아들이고 Document 목록을 출력으로 반환합니다.

리트리버 사용 방법에 대한 자세한 내용은 [여기에서 관련 방법 가이드를](https://python.langchain.com/v0.2/docs/how_to/#retrievers) 참조하세요.

### 키-값 저장소[](https://python.langchain.com/v0.2/docs/concepts/#key-value-stores "Direct link to Key-value stores")

[문서당 여러 벡터를 사용한 인덱싱 및 검색](https://python.langchain.com/v0.2/docs/how_to/multi_vector/) 또는 [임베딩 캐싱](https://python.langchain.com/v0.2/docs/how_to/caching_embeddings/)과 같은 일부 기술의 경우 KV(키-값) 스토리지 형식을 사용하는 것이 도움이 됩니다.

LangChain에는 [`BaseStore`](https://api.python.langchain.com/en/latest/stores/langchain_core.stores.BaseStore.html) 인터페이스가 포함되어 있습니다. 임의의 데이터를 저장할 수 있습니다. 그러나 KV 스토리지가 필요한 LangChain 구성 요소는 바이너리 데이터를 저장하는 보다 구체적인 인스턴스( 라고 함)를 사용하고 내부적으로 처리합니다. 특정 요구 사항에 맞게 데이터를 인코딩하고 디코딩합니다.`BaseStore[str, bytes]``ByteStore`

즉, 사용자는 다양한 유형의 데이터에 대해 다른 스토어가 아닌 한 가지 유형의 스토어만 생각하면 됩니다.

#### 인터페이스[](https://python.langchain.com/v0.2/docs/concepts/#interface "Direct link to Interface")

모든 [`BaseStore`](https://api.python.langchain.com/en/latest/stores/langchain_core.stores.BaseStore.html)는 다음 인터페이스를 지원합니다. 인터페이스는 다음을 허용합니다. **한 번에 여러** 키-값 쌍을 수정하는 경우:

- `mget(key: Sequence[str]) -> List[Optional[bytes]]`: 여러 키의 내용을 가져 와서 키가 존재하지 않는 경우 반환합니다.`None`
- `mset(key_value_pairs: Sequence[Tuple[str, bytes]]) -> None`: 여러 키의 내용을 설정합니다.
- `mdelete(key: Sequence[str]) -> None`: 여러 키 삭제
- `yield_keys(prefix: Optional[str] = None) -> Iterator[str]`: 저장소의 모든 키를 생성하며 선택적으로 접두사로 필터링합니다.

키-값 저장소 구현에 대한 자세한 내용은 [이 섹션을](https://python.langchain.com/v0.2/docs/integrations/stores/) 참조하세요.

### 도구[](https://python.langchain.com/v0.2/docs/concepts/#tools "Direct link to Tools")

도구는 모델에 의해 호출되도록 설계된 유틸리티입니다: 그들의 입력은 모델에 의해 생성되도록 설계되고, 그들의 출력은 모델로 다시 전달되도록 설계되었습니다. 모델이 코드의 일부를 제어하거나 외부 API를 호출하려는 경우 도구가 필요합니다.

도구는 다음과 같이 구성됩니다.

1. 도구의 이름입니다.
2. 도구가 수행하는 작업에 대한 설명입니다.
3. 도구에 대한 입력을 정의하는 JSON 스키마입니다.
4. 함수(및 선택적으로 함수의 비동기 변형)A function (and optionally, an async variant of the function).

도구가 모델에 바인딩되면 이름, 설명 및 JSON 스키마가 모델에 컨텍스트로 제공됩니다. 도구 목록과 명령 집합이 주어지면 모델은 특정 입력을 사용하여 하나 이상의 도구를 호출하도록 요청할 수 있습니다. 일반적인 사용법은 다음과 같습니다.

```
tools = [...] # Define a list of toolsllm_with_tools = llm.bind_tools(tools)ai_msg = llm_with_tools.invoke("do xyz...")# -> AIMessage(tool_calls=[ToolCall(...), ...], ...)
```

모델에서 반환된 것이 이와 연결되었을 수 있습니다. 응답 유형이 어떻게 생겼는지에 대한 자세한 내용은 [이 가이드를](https://python.langchain.com/v0.2/docs/concepts/#aimessage) 읽어보세요.`AIMessage``tool_calls`

선택한 도구가 호출되면 결과를 모델로 다시 전달하여 모든 작업을 완료할 수 있습니다 공연하고 있습니다. 일반적으로 도구를 호출하고 응답을 다시 전달하는 두 가지 방법이 있습니다.

#### 인수[](https://python.langchain.com/v0.2/docs/concepts/#invoke-with-just-the-arguments "Direct link to Invoke with just the arguments")만으로 호출

인자만 있는 도구를 호출하면 원시 도구 출력(일반적으로 문자열)을 다시 받게 됩니다. 일반적으로 다음과 같습니다.

```
# You will want to previously check that the LLM returned tool callstool_call = ai_msg.tool_calls[0]# ToolCall(args={...}, id=..., ...)tool_output = tool.invoke(tool_call["args"])tool_message = ToolMessage(    content=tool_output,    tool_call_id=tool_call["id"],    name=tool_call["name"])
```

필드는 일반적으로 모델로 다시 전달됩니다. 원시 도구 응답을 모델에 전달하지 않으려는 경우에도 계속 유지하려는 경우 도구 출력을 변환할 수 있지만 아티팩트로 전달할 수도 있습니다([`ToolMessage.artifact`](https://python.langchain.com/v0.2/docs/concepts/#toolmessage)에 대한 자세한 내용은 여기를 참조하세요.`content`)

```
... # Same code as aboveresponse_for_llm = transform(response)tool_message = ToolMessage(    content=response_for_llm,    tool_call_id=tool_call["id"],    name=tool_call["name"],    artifact=tool_output)
```

#### 호출 방법 [](https://python.langchain.com/v0.2/docs/concepts/#invoke-with-toolcall "Direct link to invoke-with-toolcall") `ToolCall`

도구를 호출하는 다른 방법은 모델에 의해 생성된 전체로 도구를 호출하는 것입니다. 이렇게 하면 도구에서 ToolMessage를 반환합니다. 이 방법의 장점은 도구 출력을 ToolMessage로 변환하기 위해 논리를 직접 작성할 필요가 없다는 것입니다. 일반적으로 다음과 같습니다.`ToolCall`

```
tool_call = ai_msg.tool_calls[0]# -> ToolCall(args={...}, id=..., ...)tool_message = tool.invoke(tool_call)# -> ToolMessage(    content="tool result foobar...",    tool_call_id=...,    name="tool_name")
```

이러한 방식으로 도구를 호출하고 ToolMessage에 대한 [아티팩트](https://python.langchain.com/v0.2/docs/concepts/#toolmessage)를 포함하려면 도구에서 두 가지를 반환하도록 해야 합니다. [아티팩트를 반환하는 도구를 정의하는 방법에](https://python.langchain.com/v0.2/docs/how_to/tool_artifacts/) 대한 자세한 내용은 여기를 참조하세요.

#### 권장사항[](https://python.langchain.com/v0.2/docs/concepts/#best-practices "Direct link to Best practices")

모델에서 사용할 도구를 디자인할 때 다음 사항에 유의해야 합니다.

- 명시적 [도구 호출 API](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling)가 있는 채팅 모델은 미세 조정되지 않은 모델보다 도구 호출에서 더 우수합니다.
- 도구에 잘 선택된 이름, 설명 및 JSON 스키마가 있는 경우 모델이 더 잘 수행됩니다. 이것은 프롬프트 엔지니어링의 또 다른 형태입니다.
- 단순하고 범위가 좁은 도구는 복잡한 도구보다 모델에서 더 쉽게 사용할 수 있습니다.

#### 관련[](https://python.langchain.com/v0.2/docs/concepts/#related "Direct link to Related")

도구 사용 방법에 대한 자세한 내용은 [도구 방법 가이드를](https://python.langchain.com/v0.2/docs/how_to/#tools) 참조하세요.

사전 빌드된 도구를 사용하려면 [도구 통합 문서를](https://python.langchain.com/v0.2/docs/integrations/tools/) 참조하세요.

### 툴킷[](https://python.langchain.com/v0.2/docs/concepts/#toolkits "Direct link to Toolkits")

도구 키트는 특정 작업에 함께 사용하도록 설계된 도구 모음입니다. 그들은 편리한 로딩 방법을 가지고 있습니다.

모든 툴킷은 도구 목록을 반환하는 메소드를 노출합니다. 따라서 다음을 수행할 수 있습니다.`get_tools`

```
# Initialize a toolkittoolkit = ExampleTookit(...)# Get list of toolstools = toolkit.get_tools()
```

### 에이전트[](https://python.langchain.com/v0.2/docs/concepts/#agents "Direct link to Agents")

언어 모델은 그 자체로 작업을 수행할 수 없으며 텍스트만 출력합니다. LangChain의 큰 사용 사례는 **에이전트**를 만드는 것입니다. 에이전트는 LLM을 추론 엔진으로 사용하여 어떤 작업을 수행하고 해당 작업에 대한 입력이 무엇인지 결정하는 시스템입니다. 그런 다음 이러한 작업의 결과를 에이전트에 다시 공급할 수 있으며 더 많은 작업이 필요한지 또는 완료해도 되는지 여부를 결정합니다.

[LangGraph](https://github.com/langchain-ai/langgraph)는 LangChain의 확장으로, 특히 고도로 제어 가능하고 사용자 정의 가능한 에이전트를 만드는 것을 목표로 합니다. 에이전트 개념에 대한 자세한 개요는 해당 설명서를 확인하세요.

LangChain에는 더 이상 사용되지 않는 방향으로 나아가고 있는 레거시 에이전트 개념이 있습니다. AgentExecutor는 본질적으로 에이전트의 런타임이었습니다. 시작하기에 좋은 곳이었지만 더 많은 사용자 지정 에이전트를 사용하기 시작하면서 충분히 유연하지 않았습니다. 이 문제를 해결하기 위해 우리는 LangGraph를 유연하고 고도로 제어 가능한 런타임으로 구축했습니다.`AgentExecutor`

아직도 AgentExecutor를 사용하고 있다면, 두려워하지 마십시오: [AgentExecutor 사용 방법에](https://python.langchain.com/v0.2/docs/how_to/agent_executor/) 대한 가이드가 아직 있습니다. 그러나 LangGraph로 전환을 시작하는 것이 좋습니다. 이를 지원하기 위해 [우리는 그렇게 하는 방법에 대한 전환 가이드를 마련했습니다](https://python.langchain.com/v0.2/docs/how_to/migrate_agent/).

#### ReAct 에이전트[](https://python.langchain.com/v0.2/docs/concepts/#react-agents "Direct link to ReAct agents")

빌딩 에이전트에 널리 사용되는 아키텍처 중 하나는 [**ReAct**](https://arxiv.org/abs/2210.03629)입니다. ReAct는 추론과 행동을 반복적인 과정으로 결합합니다 - 실제로 "ReAct"라는 이름은 "Reason"과 "Act"의 약자입니다.

일반적인 흐름은 다음과 같습니다.

- 모델은 입력 및 이전 관찰에 대한 응답으로 어떤 단계를 수행해야 하는지에 대해 "생각"합니다.
- 그런 다음 모델은 사용 가능한 도구에서 작업을 선택합니다(또는 사용자에게 응답하도록 선택).
- 모델은 해당 도구에 대한 인수를 생성합니다.
- 에이전트 런타임(실행기)은 선택한 도구를 구문 분석하고 생성된 인수로 호출합니다.
- 실행기는 도구 호출의 결과를 관찰로 모델에 다시 반환합니다.
- 이 프로세스는 에이전트가 응답하도록 선택할 때까지 반복됩니다.

모델별 기능이 필요하지 않은 일반적인 프롬프트 기반 구현이 있지만 가장 많은 신뢰할 수 있는 구현은 [도구 호출](https://python.langchain.com/v0.2/docs/how_to/tool_calling/)과 같은 기능을 사용하여 출력 형식을 안정적으로 지정합니다 분산을 줄입니다.

자세한 내용은 [LangGraph 설명서를](https://langchain-ai.github.io/langgraph/) 참조하세요. 또는 [이 방법 가이드에서](https://python.langchain.com/v0.2/docs/how_to/migrate_agent/) LangGraph로 마이그레이션하는 방법에 대한 구체적인 정보를 확인할 수 있습니다.

### 콜백을[](https://python.langchain.com/v0.2/docs/concepts/#callbacks "Direct link to Callbacks")

LangChain은 LLM 애플리케이션의 다양한 단계에 연결할 수 있는 콜백 시스템을 제공합니다. 이는 로깅, 모니터링, 스트리밍 및 기타 작업에 유용합니다.

API 전체에서 사용할 수 있는 인수를 사용하여 이러한 이벤트를 구독할 수 있습니다. 이 인자는 처리기 객체의 목록으로, 아래에 설명된 하나 이상의 메소드를 더 자세히 구현할 것으로 예상됩니다.`callbacks`

#### 콜백 이벤트[](https://python.langchain.com/v0.2/docs/concepts/#callback-events "Direct link to Callback Events")

|이벤트|이벤트 트리거|관련 방법|
|---|---|---|
|채팅 모델 시작|채팅 모델이 시작될 때|`on_chat_model_start`|
|LLM 시작|LLM이 시작될 때|`on_llm_start`|
|LLM 새 토큰|llm OR 채팅 모델이 새 토큰을 내보내는 경우|`on_llm_new_token`|
|LLM 종료|llm OR 채팅 모델이 종료될 때|`on_llm_end`|
|LLM 오류|llm OR 채팅 모델에 오류가 있을 때|`on_llm_error`|
|체인 시작|체인이 작동하기 시작할 때|`on_chain_start`|
|체인 끝|체인이 끝날 때|`on_chain_end`|
|체인 오류|체인에 오류가 있을 때|`on_chain_error`|
|공구 시작|도구가 실행되기 시작할 때|`on_tool_start`|
|공구 끝|공구가 종료될 때|`on_tool_end`|
|공구 오류|공구에 오류가 있을 때|`on_tool_error`|
|에이전트 작업|에이전트가 작업을 수행하는 경우|`on_agent_action`|
|에이전트 마침|에이전트가 종료되는 경우|`on_agent_finish`|
|리트리버 시작|리트리버가 시작될 때|`on_retriever_start`|
|리트리버 끝|리트리버가 끝날 때|`on_retriever_end`|
|리트리버 오류|리트리버가 오류를 범할 때|`on_retriever_error`|
|문자 메시지|임의의 텍스트가 실행되는 경우|`on_text`|
|재시도|재시도 이벤트가 실행되는 경우|`on_retry`|

#### 콜백 처리기[](https://python.langchain.com/v0.2/docs/concepts/#callback-handlers "Direct link to Callback handlers")

콜백 핸들러는 다음과 같을 수 있습니다.`sync``async`

- 동기화 콜백 핸들러는 [BaseCallbackHandler](https://api.python.langchain.com/en/latest/callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html) 인터페이스를 구현합니다.
- 비동기 콜백 핸들러는 [AsyncCallbackHandler](https://api.python.langchain.com/en/latest/callbacks/langchain_core.callbacks.base.AsyncCallbackHandler.html) 인터페이스를 구현합니다.

런타임 동안 LangChain은 적절한 콜백 관리자(예: [CallbackManager](https://api.python.langchain.com/en/latest/callbacks/langchain_core.callbacks.manager.CallbackManager.html) 또는 [AsyncCallbackManager](https://api.python.langchain.com/en/latest/callbacks/langchain_core.callbacks.manager.AsyncCallbackManager.html))를 구성하며, 이벤트가 트리거될 때 각 "등록된" 콜백 핸들러에서 적절한 메서드를 호출합니다.

#### 콜백 전달하기[](https://python.langchain.com/v0.2/docs/concepts/#passing-callbacks "Direct link to Passing callbacks")

이 속성은 다음 두 위치에서 API 전체의 대부분의 개체(모델, 도구, 에이전트 등)에서 사용할 수 있습니다.`callbacks`

콜백은 API의 두 가지 다른 위치에서 대부분의 개체(모델, 도구, 에이전트 등)에서 사용할 수 있습니다.

- **요청 시간 콜백**: 입력 데이터 외에 요청 시 전달됩니다. 모든 표준 개체에서 사용할 수 있습니다. 이러한 콜백은 모든 자식에 의해 상속됩니다 그들이 정의된 개체의. 예를 들어.`Runnable``chain.invoke({"number": 25}, {"callbacks": [handler]})`
- **생성자 콜백**: . 이러한 콜백 객체의 생성자에 인수로 전달됩니다. 콜백의 범위가 지정됩니다 그들이 정의 된 객체에만 적용되며 객체의 자식에 의해 상속**되지 않습니다**.`chain = TheNameOfSomeChain(callbacks=[handler])`

위험

생성자 콜백의 범위는 해당 콜백이 정의된 객체로만 지정됩니다. 자식에 의해 상속**되지 않습니다** 개체의.

사용자 지정 체인 또는 실행 가능 항목을 만드는 경우 요청 시간을 전파하는 것을 기억해야 합니다 모든 자식 객체에 대한 콜백.

파이썬의 비동기 < = 3.10

다른 실행 가능 항목을 호출하는 모든 , a 또는 python<=3.10에서 async를 실행 중이며 콜백을 자식에게 전파해야 합니다. 개체를 수동으로 사용할 수 있습니다. 이는 LangChain이 자동으로 전파할 수 없기 때문입니다 이 경우 자식 객체에 대한 콜백입니다.`RunnableLambda``RunnableGenerator``Tool`

이는 사용자 지정에서 내보내는 이벤트를 못할 수 있는 일반적인 이유입니다 runnables 또는 도구.

콜백 사용 방법에 대한 자세한 내용은 [여기에서 관련 방법 가이드를](https://python.langchain.com/v0.2/docs/how_to/#callbacks) 참조하세요.

## 기술을[](https://python.langchain.com/v0.2/docs/concepts/#techniques "Direct link to Techniques")

### 스트리밍[](https://python.langchain.com/v0.2/docs/concepts/#streaming "Direct link to Streaming")

개별 LLM 호출은 기존 리소스 요청보다 훨씬 더 오래 실행되는 경우가 많습니다. 이는 여러 추론 단계가 필요한 더 복잡한 체인이나 에이전트를 구축할 때 복잡해집니다.

Fortunately, LLMs generate output iteratively, which means it's possible to show sensible intermediate results before the final response is ready. Consuming output as soon as it becomes available has therefore become a vital part of the UX around building apps with LLMs to help alleviate latency issues, and LangChain aims to have first-class support for streaming.

Below, we'll discuss some concepts and considerations around streaming in LangChain.

#### `.stream()` and [​](https://python.langchain.com/v0.2/docs/concepts/#stream-and-astream "Direct link to stream-and-astream")`.astream()`

LangChain의 대부분의 모듈에는 이 메서드(및 [비동기](https://docs.python.org/3/library/asyncio.html) 환경의 경우 동일한 메서드)가 인체공학적 스트리밍 인터페이스로 포함되어 있습니다. 간단한 루프로 사용할 수 있는 반복자를 반환합니다. 다음은 채팅 모델의 예입니다.`.stream()``.astream()``.stream()``for`

```
from langchain_anthropic import ChatAnthropicmodel = ChatAnthropic(model="claude-3-sonnet-20240229")for chunk in model.stream("what color is the sky?"):    print(chunk.content, end="|", flush=True)
```

**API 참조:**[ChatAnthropic](https://api.python.langchain.com/en/latest/chat_models/langchain_anthropic.chat_models.ChatAnthropic.html)

기본적으로 스트리밍을 지원하지 않는 모델(또는 다른 구성 요소)의 경우 이 반복자는 단일 청크만 생성하지만 호출 할 때 동일한 일반 패턴을 계속 사용할 수 있습니다. 또한 Using은 스트리밍 모드에서 모델을 자동으로 호출합니다. 추가 구성을 제공할 필요가 없습니다.`.stream()`

출력되는 각 청크의 유형은 컴포넌트의 유형에 따라 다릅니다 - 예를 들어, 채팅 모델은 [`AIMessageChunks를`](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.ai.AIMessageChunk.html) 생성합니다. 이 메서드는 [LangChain 표현식 언어](https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel)의 일부이므로 [output parser](https://python.langchain.com/v0.2/docs/concepts/#output-parsers)를 사용하여 변환하여 다른 출력의 형식 차이를 처리할 수 있습니다 각 덩어리가 생성되었습니다.

사용 방법에 대한 자세한 내용은 [이 가이드를](https://python.langchain.com/v0.2/docs/how_to/streaming/#using-stream) 확인할 수 있습니다.`.stream()`

#### `.astream_events()`[​](https://python.langchain.com/v0.2/docs/concepts/#astream_events "Direct link to astream_events")

이 방법은 직관적이지만 체인의 최종 생성 값만 반환할 수 있습니다. 이것은 단일 LLM 호출에 적합합니다. 그러나 여러 LLM 호출의 더 복잡한 체인을 함께 구축함에 따라 중간 값을 사용하고 싶을 수 있습니다. 최종 출력과 함께 체인 - 예를 들어, 채팅을 구축할 때 최종 생성과 함께 소스를 반환합니다. 문서 앱을 통해.`.stream()`

[콜백을 사용하거나](https://python.langchain.com/v0.2/docs/concepts/#callbacks-1) 중간을 전달하는 방식으로 체인을 구성하여 이 작업을 수행하는 방법이 있습니다 값을 chained [`.assign()`](https://python.langchain.com/v0.2/docs/how_to/passthrough/) 호출과 같은 것으로 끝낼 수 있지만 LangChain에는 콜백의 유연성과 의 인체 공학을 결합한 메서드도 포함되어 있습니다. 호출되면 반복자를 반환합니다 이에 따라 필터링하고 처리할 수 있는 [다양한 유형의 이벤트를](https://python.langchain.com/v0.2/docs/how_to/streaming/#event-reference) 생성합니다 프로젝트의 필요에 따라.`.astream_events()``.stream()`

다음은 스트리밍된 채팅 모델 출력을 포함하는 이벤트만 인쇄하는 작은 예입니다.

```
from langchain_core.output_parsers import StrOutputParserfrom langchain_core.prompts import ChatPromptTemplatefrom langchain_anthropic import ChatAnthropicmodel = ChatAnthropic(model="claude-3-sonnet-20240229")prompt = ChatPromptTemplate.from_template("tell me a joke about {topic}")parser = StrOutputParser()chain = prompt | model | parserasync for event in chain.astream_events({"topic": "parrot"}, version="v2"):    kind = event["event"]    if kind == "on_chat_model_stream":        print(event, end="|", flush=True)
```

**API 참조:**[StrOutputParser](https://api.python.langchain.com/en/latest/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPrompt템플릿](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html) | [ChatAnthropic](https://api.python.langchain.com/en/latest/chat_models/langchain_anthropic.chat_models.ChatAnthropic.html) 님

대략적으로 콜백 이벤트에 대한 반복자로 생각할 수 있으며 (형식은 다르지만) 거의 모든 LangChain 구성 요소에서 사용할 수 있습니다!

사용 방법에 대한 자세한 내용은 [이 가이드를](https://python.langchain.com/v0.2/docs/how_to/streaming/#using-stream-events) 참조하십시오. 사용 가능한 이벤트를 나열하는 테이블을 포함합니다.`.astream_events()`

#### 콜백을[](https://python.langchain.com/v0.2/docs/concepts/#callbacks-1 "Direct link to Callbacks")

LangChain의 LLM에서 출력을 스트리밍하는 가장 낮은 수준의 방법은 [콜백](https://python.langchain.com/v0.2/docs/concepts/#callbacks) 시스템을 사용하는 것입니다. 다음을 전달할 수 있습니다. [`on_llm_new_token`](https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.html#langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.on_llm_new_token) 이벤트를 LangChain 구성 요소로 처리하는 callback 핸들러입니다. 해당 컴포넌트가 호출되면 컴포넌트에 포함된 모든 [LLM](https://python.langchain.com/v0.2/docs/concepts/#llms) 또는 [채팅 모델이](https://python.langchain.com/v0.2/docs/concepts/#chat-models) 호출됩니다. 생성된 토큰이 있는 콜백입니다. 콜백 내에서 토큰을 다른 대상(예: HTTP 응답)으로 파이프할 수 있습니다. [`on_llm_end`](https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.html#langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.on_llm_end) 이벤트를 처리하여 필요한 정리를 수행할 수도 있습니다.

콜백 사용에 대한 자세한 내용은 [이 방법 섹션을](https://python.langchain.com/v0.2/docs/how_to/#callbacks) 참조하십시오.

Callbacks were the first technique for streaming introduced in LangChain. While powerful and generalizable, they can be unwieldy for developers. For example:

- You need to explicitly initialize and manage some aggregator or other stream to collect results.
- The execution order isn't explicitly guaranteed, and you could theoretically have a callback run after the method finishes.`.invoke()`
- Providers would often make you pass an additional parameter to stream outputs instead of returning them all at once.
- You would often ignore the result of the actual model call in favor of callback results.

#### Tokens[​](https://python.langchain.com/v0.2/docs/concepts/#tokens "Direct link to Tokens")

대부분의 모델 공급자가 입력 및 출력을 측정하는 데 사용하는 단위는 **토큰**이라는 단위를 통해 이루어집니다. 토큰은 언어 모델이 텍스트를 처리하거나 생성할 때 읽고 생성하는 기본 단위입니다. 토큰의 정확한 정의는 모델이 학습된 특정 방식에 따라 달라질 수 있습니다. 예를 들어 영어에서 토큰은 "apple"과 같은 단일 단어 또는 "app"과 같은 단어의 일부일 수 있습니다.

모델에 프롬프트를 보내면 프롬프트의 단어와 문자가 **토크나이저를** 사용하여 토큰으로 인코딩됩니다. 그런 다음 모델은 생성된 출력 토큰을 다시 스트리밍하며, 토크나이저는 이를 사람이 읽을 수 있는 텍스트로 디코딩합니다. 아래 예는 OpenAI 모델이 토큰화하는 방법을 보여줍니다.`LangChain is cool!`

![](https://python.langchain.com/v0.2/assets/images/tokenization-10f566ab6774724e63dd99646f69655c.png)

5개의 다른 토큰으로 분할되고 토큰 간의 경계가 단어 경계와 정확히 동일하지 않음을 알 수 있습니다.

언어 모델이 "문자"와 같이 즉각적으로 직관적인 것이 아닌 토큰을 사용하는 이유 텍스트를 처리하고 이해하는 방법과 관련이 있습니다. 상위 수준에서, 언어 모델은 다음을 기반으로 다음에 생성된 출력을 반복적으로 예측합니다. 초기 입력 및 이전 세대. 언어를 처리하기 위해 토큰 언어 모델을 사용하여 모델 학습 개별 문자가 아닌 의미를 전달하는 단위(예: 단어 또는 하위 단어)는 모델을 더 쉽게 만듭니다. 문법과 문맥을 포함한 언어의 구조를 배우고 이해합니다. 또한 토큰을 사용하면 모델이 문자 수준 처리에 비해 더 적은 텍스트 단위를 처리하기 때문에 효율성이 향상될 수도 있습니다.

### 함수/도구 호출[](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling "Direct link to Function/tool calling")

정보

도구 호출이라는 용어는 함수 호출과 같은 의미로 사용됩니다. 있지만 함수 호출은 때때로 단일 함수의 호출을 참조하기 위한 것입니다. 우리는 모든 모델을 여러 도구 또는 함수 호출을 반환할 수 있는 것처럼 취급합니다 각 메시지.

도구 호출을 사용하면 [채팅 모델이](https://python.langchain.com/v0.2/docs/concepts/#chat-models) 다음과 같은 출력을 생성하여 주어진 프롬프트에 응답할 수 있습니다. 사용자 정의 스키마와 일치합니다.

이름은 모델이 수행되고 있음을 암시합니다. 일부 조치, 이것은 실제로 사실이 아닙니다! 모델은 도구에 대한 인수만 생성하며 실제로 도구를 실행(또는 실행하지 않음)은 사용자에게 달려 있습니다. 생성된 인수를 사용하여 함수를 호출하고 싶지 **않은** 일반적인 예 중 하나입니다 구조화되지 않은 텍스트에서 [일부 스키마와 일치하는 구조화된 출력을 추출](https://python.langchain.com/v0.2/docs/concepts/#structured-output)하려는 경우입니다. 모델에 "추출"도구를 제공합니다. 원하는 스키마와 일치하는 매개 변수를 선택한 다음 생성된 출력을 최종 출력으로 처리합니다. 결과.

![채팅 모델에 의한 도구 호출 다이어그램Diagram of a tool call by a chat model](https://python.langchain.com/v0.2/assets/images/tool_call-8d4a8b18e90cacd03f62e94071eceace.png)

Tool calling is not universal, but is supported by many popular LLM providers, including [Anthropic](https://python.langchain.com/v0.2/docs/integrations/chat/anthropic/), [Cohere](https://python.langchain.com/v0.2/docs/integrations/chat/cohere/), [Google](https://python.langchain.com/v0.2/docs/integrations/chat/google_vertex_ai_palm/), [Mistral](https://python.langchain.com/v0.2/docs/integrations/chat/mistralai/), [OpenAI](https://python.langchain.com/v0.2/docs/integrations/chat/openai/), and even for locally-running models via [Ollama](https://python.langchain.com/v0.2/docs/integrations/chat/ollama/).

LangChain provides a standardized interface for tool calling that is consistent across different models.

The standard interface consists of:

- `ChatModel.bind_tools()`: a method for specifying which tools are available for a model to call. This method accepts [LangChain tools](https://python.langchain.com/v0.2/docs/concepts/#tools) as well as [Pydantic](https://pydantic.dev/) objects.
- `AIMessage.tool_calls`: an attribute on the returned from the model for accessing the tool calls requested by the model.`AIMessage`

#### Tool usage[​](https://python.langchain.com/v0.2/docs/concepts/#tool-usage "Direct link to Tool usage")

After the model calls tools, you can use the tool by invoking it, then passing the arguments back to the model. LangChain provides the [`Tool`](https://python.langchain.com/v0.2/docs/concepts/#tools) abstraction to help you handle this.

The general flow is this:

1. Generate tool calls with a chat model in response to a query.
2. Invoke the appropriate tools using the generated tool call as arguments.
3. Format the result of the tool invocations as [`ToolMessages`](https://python.langchain.com/v0.2/docs/concepts/#toolmessage).
4. Pass the entire list of messages back to the model so that it can generate a final answer (or call more tools).

![Diagram of a complete tool calling flow](https://python.langchain.com/v0.2/assets/images/tool_calling_flow-ead8d93a8b69c88e3076457ed28f41ae.png)

This is how tool calling [agents](https://python.langchain.com/v0.2/docs/concepts/#agents) perform tasks and answer queries.

Check out some more focused guides below:

- [How to use chat models to call tools](https://python.langchain.com/v0.2/docs/how_to/tool_calling/)
- [How to pass tool outputs to chat models](https://python.langchain.com/v0.2/docs/how_to/tool_results_pass_to_model/)
- [Building an agent with LangGraph](https://langchain-ai.github.io/langgraph/tutorials/introduction/)

### Structured output[​](https://python.langchain.com/v0.2/docs/concepts/#structured-output "Direct link to Structured output")

LLMs are capable of generating arbitrary text. This enables the model to respond appropriately to a wide range of inputs, but for some use-cases, it can be useful to constrain the LLM's output to a specific format or structure. This is referred to as **structured output**.

For example, if the output is to be stored in a relational database, it is much easier if the model generates output that adheres to a defined schema or format. [Extracting specific information](https://python.langchain.com/v0.2/docs/tutorials/extraction/) from unstructured text is another case where this is particularly useful. Most commonly, the output format will be JSON, though other formats such as [YAML](https://python.langchain.com/v0.2/docs/how_to/output_parser_yaml/) can be useful too. Below, we'll discuss a few ways to get structured output from models in LangChain.

#### `.with_structured_output()`[​](https://python.langchain.com/v0.2/docs/concepts/#with_structured_output "Direct link to with_structured_output")

For convenience, some LangChain chat models support a [`.with_structured_output()`](https://python.langchain.com/v0.2/docs/how_to/structured_output/#the-with_structured_output-method) method. This method only requires a schema as input, and returns a dict or Pydantic object. Generally, this method is only present on models that support one of the more advanced methods described below, and will use one of them under the hood. It takes care of importing a suitable output parser and formatting the schema in the right format for the model.

Here's an example:

```
from typing import Optionalfrom langchain_core.pydantic_v1 import BaseModel, Fieldclass Joke(BaseModel):    """Joke to tell user."""    setup: str = Field(description="The setup of the joke")    punchline: str = Field(description="The punchline to the joke")    rating: Optional[int] = Field(description="How funny the joke is, from 1 to 10")structured_llm = llm.with_structured_output(Joke)structured_llm.invoke("Tell me a joke about cats")
```

```
Joke(setup='Why was the cat sitting on the computer?', punchline='To keep an eye on the mouse!', rating=None)
```

We recommend this method as a starting point when working with structured output:

- It uses other model-specific features under the hood, without the need to import an output parser.
- For the models that use tool calling, no special prompting is needed.
- If multiple underlying techniques are supported, you can supply a parameter to [toggle which one is used](https://python.langchain.com/v0.2/docs/how_to/structured_output/#advanced-specifying-the-method-for-structuring-outputs).`method`

You may want or need to use other techniques if:

- The chat model you are using does not support tool calling.
- You are working with very complex schemas and the model is having trouble generating outputs that conform.

For more information, check out this [how-to guide](https://python.langchain.com/v0.2/docs/how_to/structured_output/#the-with_structured_output-method).

You can also check out [this table](https://python.langchain.com/v0.2/docs/integrations/chat/#advanced-features) for a list of models that support .`with_structured_output()`

#### Raw prompting[​](https://python.langchain.com/v0.2/docs/concepts/#raw-prompting "Direct link to Raw prompting")

The most intuitive way to get a model to structure output is to ask nicely. In addition to your query, you can give instructions describing what kind of output you'd like, then parse the output using an [output parser](https://python.langchain.com/v0.2/docs/concepts/#output-parsers) to convert the raw model message or string output into something more easily manipulated.

The biggest benefit to raw prompting is its flexibility:

- Raw prompting does not require any special model features, only sufficient reasoning capability to understand the passed schema.
- You can prompt for any format you'd like, not just JSON. This can be useful if the model you are using is more heavily trained on a certain type of data, such as XML or YAML.

However, there are some drawbacks too:

- LLMs are non-deterministic, and prompting a LLM to consistently output data in the exactly correct format for smooth parsing can be surprisingly difficult and model-specific.
- 개별 모델에는 훈련된 데이터에 따라 단점이 있으며 프롬프트를 최적화하는 것은 매우 어려울 수 있습니다. 일부는 [JSON 스키마](https://json-schema.org/)를 더 잘 해석할 수 있고, 다른 일부는 TypeScript 정의에 가장 적합할 수 있습니다. 또 다른 사람들은 XML을 선호할 수 있습니다.

모델 공급자가 제공하는 기능은 안정성을 높일 수 있지만 프롬프트 기술은 튜닝에 여전히 중요합니다. 어떤 방법을 선택하든 결과.

#### JSON 모드[](https://python.langchain.com/v0.2/docs/concepts/#json-mode "Direct link to JSON mode")

[미스트랄(Mistral](https://python.langchain.com/v0.2/docs/integrations/chat/mistralai/)), [오픈AI(OpenAI](https://python.langchain.com/v0.2/docs/integrations/chat/openai/)), [투게더 AI(Together AI](https://python.langchain.com/v0.2/docs/integrations/chat/together/)), [올라마(Ollama](https://python.langchain.com/v0.2/docs/integrations/chat/ollama/)) 등 일부 모델, 일반적으로 구성을 통해 활성화되는 **JSON 모드**라는 기능을 지원합니다.

활성화되면 JSON 모드는 모델의 출력을 항상 일종의 유효한 JSON으로 제한합니다. 종종 그들은 몇 가지 사용자 정의 프롬프트가 필요하지만 일반적으로 완전히 원시 프롬프트보다 훨씬 덜 부담스럽습니다. 의 라인을 따라 더 많이, . [출력은 일반적으로 구문 분석하기가 더 쉽습니다](https://python.langchain.com/v0.2/docs/how_to/output_parser_json/).`"you must always return JSON"`

또한 일반적으로 도구 호출보다 직접 사용하는 것이 더 간단하고 더 일반적으로 사용할 수 있으며 다음을 제공할 수 있습니다. 도구 호출보다 결과를 프롬프트하고 형성하는 데 더 많은 유연성이 있습니다.

예를 들면 다음과 같습니다.

```
from langchain_core.prompts import ChatPromptTemplatefrom langchain_openai import ChatOpenAIfrom langchain.output_parsers.json import SimpleJsonOutputParsermodel = ChatOpenAI(    model="gpt-4o",    model_kwargs={ "response_format": { "type": "json_object" } },)prompt = ChatPromptTemplate.from_template(    "Answer the user's question to the best of your ability."    'You must always output a JSON object with an "answer" key and a "followup_question" key.'    "{question}")chain = prompt | model | SimpleJsonOutputParser()chain.invoke({ "question": "What is the powerhouse of the cell?" })
```

**API 참조:**[ChatPromptTemplate](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html) | [챗오픈AI](https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html) | [SimpleJsonOutputParser (SimpleJsonOutput파서)](https://api.python.langchain.com/en/latest/output_parsers/langchain_core.output_parsers.json.SimpleJsonOutputParser.html)

```
{'answer': 'The powerhouse of the cell is the mitochondrion. It is responsible for producing energy in the form of ATP through cellular respiration.', 'followup_question': 'Would you like to know more about how mitochondria produce energy?'}
```

JSON 모드를 지원하는 모델 공급자의 전체 목록은 [이 표를](https://python.langchain.com/v0.2/docs/integrations/chat/#advanced-features) 참조하세요.

#### 툴 호출[](https://python.langchain.com/v0.2/docs/concepts/#structured-output-tool-calling "Direct link to Tool calling")

이를 지원하는 모델의 경우 [도구 호출](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling)은 구조화된 출력에 매우 편리할 수 있습니다. 그것은 제거한다 기본 제공 모델 기능을 위해 스키마를 프롬프트하는 가장 좋은 방법에 대한 추측.

먼저 원하는 스키마를 직접 또는 [LangChain 도구를](https://python.langchain.com/v0.2/docs/concepts/#tools) 통해 메소드를 사용하여 [채팅 모델에](https://python.langchain.com/v0.2/docs/concepts/#chat-models) 바인딩하여 작동합니다. 그런 다음 모델은 다음을 포함합니다. 원하는 모양과 일치하는 필드입니다.`.bind_tools()``AIMessage``tool_calls``args`

LangChain에서 모델에 도구를 바인딩하는 데 사용할 수 있는 몇 가지 형식이 있습니다. 한 가지 예를 들면 다음과 같습니다.

```
from langchain_core.pydantic_v1 import BaseModel, Fieldfrom langchain_openai import ChatOpenAIclass ResponseFormatter(BaseModel):    """Always use this tool to structure your response to the user."""    answer: str = Field(description="The answer to the user's question")    followup_question: str = Field(description="A followup question the user could ask")model = ChatOpenAI(    model="gpt-4o",    temperature=0,)model_with_tools = model.bind_tools([ResponseFormatter])ai_msg = model_with_tools.invoke("What is the powerhouse of the cell?")ai_msg.tool_calls[0]["args"]
```

**API Reference:**[ChatOpenAI](https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)

```
{'answer': "The powerhouse of the cell is the mitochondrion. It generates most of the cell's supply of adenosine triphosphate (ATP), which is used as a source of chemical energy.", 'followup_question': 'How do mitochondria generate ATP?'}
```

Tool calling is a generally consistent way to get a model to generate structured output, and is the default technique used for the [`.with_structured_output()`](https://python.langchain.com/v0.2/docs/concepts/#with_structured_output) method when a model supports it.

The following how-to guides are good practical resources for using function/tool calling for structured output:

- [How to return structured data from an LLM](https://python.langchain.com/v0.2/docs/how_to/structured_output/)
- [How to use a model to call tools](https://python.langchain.com/v0.2/docs/how_to/tool_calling/)

For a full list of model providers that support tool calling, [see this table](https://python.langchain.com/v0.2/docs/integrations/chat/#advanced-features).

### Retrieval[​](https://python.langchain.com/v0.2/docs/concepts/#retrieval "Direct link to Retrieval")

LLMs are trained on a large but fixed dataset, limiting their ability to reason over private or recent information. Fine-tuning an LLM with specific facts is one way to mitigate this, but is often [poorly suited for factual recall](https://www.anyscale.com/blog/fine-tuning-is-for-form-not-facts) and [can be costly](https://www.glean.com/blog/how-to-build-an-ai-assistant-for-the-enterprise). Retrieval is the process of providing relevant information to an LLM to improve its response for a given input. Retrieval augmented generation (RAG) is the process of grounding the LLM generation (output) using the retrieved information.

TIP

- See our RAG from Scratch [code](https://github.com/langchain-ai/rag-from-scratch) and [video series](https://youtube.com/playlist?list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x&feature=shared).
- For a high-level guide on retrieval, see this [tutorial on RAG](https://python.langchain.com/v0.2/docs/tutorials/rag/).

RAG is only as good as the retrieved documents’ relevance and quality. Fortunately, an emerging set of techniques can be employed to design and improve RAG systems. We've focused on taxonomizing and summarizing many of these techniques (see below figure) and will share some high-level strategic guidance in the following sections. You can and should experiment with using different pieces together. You might also find [this LangSmith guide](https://docs.smith.langchain.com/how_to_guides/evaluation/evaluate_llm_application) useful for showing how to evaluate different iterations of your app.

![](https://python.langchain.com/v0.2/assets/images/rag_landscape-627f1d0fd46b92bc2db0af8f99ec3724.png)

#### Query Translation[​](https://python.langchain.com/v0.2/docs/concepts/#query-translation "Direct link to Query Translation")

First, consider the user input(s) to your RAG system. Ideally, a RAG system can handle a wide range of inputs, from poorly worded questions to complex multi-part queries. **Using an LLM to review and optionally modify the input is the central idea behind query translation.** This serves as a general buffer, optimizing raw user inputs for your retrieval system. For example, this can be as simple as extracting keywords or as complex as generating multiple sub-questions for a complex query.

|Name|When to use|Description|
|---|---|---|
|[Multi-query](https://python.langchain.com/v0.2/docs/how_to/MultiQueryRetriever/)|When you need to cover multiple perspectives of a question.|Rewrite the user question from multiple perspectives, retrieve documents for each rewritten question, return the unique documents for all queries.|
|[Decomposition](https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb)|When a question can be broken down into smaller subproblems.|Decompose a question into a set of subproblems / questions, which can either be solved sequentially (use the answer from first + retrieval to answer the second) or in parallel (consolidate each answer into final answer).|
|[Step-back](https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb)|When a higher-level conceptual understanding is required.|First prompt the LLM to ask a generic step-back question about higher-level concepts or principles, and retrieve relevant facts about them. Use this grounding to help answer the user question.|
|[HyDE](https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb)|If you have challenges retrieving relevant documents using the raw user inputs.|Use an LLM to convert questions into hypothetical documents that answer the question. Use the embedded hypothetical documents to retrieve real documents with the premise that doc-doc similarity search can produce more relevant matches.|

TIP

See our RAG from Scratch videos for a few different specific approaches:

- [Multi-query](https://youtu.be/JChPi0CRnDY?feature=shared)
- [Decomposition](https://youtu.be/h0OPWlEOank?feature=shared)
- [Step-back](https://youtu.be/xn1jEjRyJ2U?feature=shared)
- [HyDE](https://youtu.be/SaDzIVkYqyY?feature=shared)

#### Routing[​](https://python.langchain.com/v0.2/docs/concepts/#routing "Direct link to Routing")

둘째, RAG 시스템에서 사용할 수 있는 데이터 소스를 고려하십시오. 둘 이상의 데이터베이스 또는 구조화된 데이터 원본과 구조화되지 않은 데이터 원본에서 쿼리하려고 합니다. **LLM을 사용하여 입력을 검토하고 적절한 데이터 소스로 라우팅하는 것은 소스 간 쿼리를 위한 간단하고 효과적인 접근 방식입니다.**

|이름|사용 시기|묘사|
|---|---|---|
|[논리적 라우팅](https://python.langchain.com/v0.2/docs/how_to/routing/)|입력을 라우팅할 위치를 결정하기 위해 LLM에 규칙을 프롬프트할 수 있는 경우.|논리적 라우팅은 LLM을 사용하여 쿼리에 대해 추론하고 가장 적합한 데이터스토어를 선택할 수 있습니다.|
|[시맨틱 라우팅(Semantic Routing)](https://python.langchain.com/v0.2/docs/how_to/routing/#routing-by-semantic-similarity)|의미론적 유사성이 입력을 라우팅할 위치를 결정하는 효과적인 방법인 경우.|의미 체계 라우팅은 쿼리와 일반적으로 프롬프트 집합을 모두 포함합니다. 그런 다음 유사성에 따라 적절한 프롬프트를 선택합니다.|

팁

[라우팅](https://youtu.be/pfpIndq7Fi8?feature=shared)에 대한 RAG from Scratch 비디오를 참조하십시오.

#### 쿼리 생성[](https://python.langchain.com/v0.2/docs/concepts/#query-construction "Direct link to Query Construction")

셋째, 데이터 원본에 특정 쿼리 형식이 필요한지 여부를 고려합니다. 많은 구조화된 데이터베이스는 SQL을 사용합니다. 벡터 스토어에는 문서 메타데이터에 키워드 필터를 적용하기 위한 특정 구문이 있는 경우가 많습니다. **LLM을 사용하여 자연어 쿼리를 쿼리 구문으로 변환하는 것은 널리 사용되는 강력한 접근 방식입니다.** 특히 [text-to-SQL](https://python.langchain.com/v0.2/docs/tutorials/sql_qa/), [text-to-Cypher](https://python.langchain.com/v0.2/docs/tutorials/graph/) 및 [메타데이터 필터에 대한 쿼리 분석](https://python.langchain.com/v0.2/docs/tutorials/query_analysis/#query-analysis)은 각각 정형, 그래프 및 벡터 데이터베이스와 상호 작용하는 유용한 방법입니다.

|이름|사용 시기|묘사|
|---|---|---|
|[텍스트를 SQL로](https://python.langchain.com/v0.2/docs/tutorials/sql_qa/)|사용자가 SQL을 통해 액세스할 수 있는 관계형 데이터베이스에 저장된 정보가 필요한 질문을 하는 경우.|이는 LLM을 사용하여 사용자 입력을 SQL 쿼리로 변환합니다.|
|[Text-to-Cypher (텍스트-사이퍼)](https://python.langchain.com/v0.2/docs/tutorials/graph/)|사용자가 Cypher를 통해 액세스할 수 있는 그래프 데이터베이스에 저장된 정보가 필요한 질문을 하는 경우.|LLM을 사용하여 사용자 입력을 Cypher 쿼리로 변환합니다.|
|[자체 쿼리](https://python.langchain.com/v0.2/docs/how_to/self_query/)|사용자가 텍스트와의 유사성보다는 메타데이터를 기반으로 문서를 가져와 더 나은 답변을 제공하는 질문을 하는 경우.|이는 LLM을 사용하여 사용자 입력을 두 가지로 변환합니다: (1) 의미론적으로 조회할 문자열, (2) 이와 함께 사용할 메타데이터 필터. 이것은 종종 질문이 문서의 METADATA(콘텐츠 자체가 아님)에 관한 것이기 때문에 유용합니다.|

팁

[쿼리 생성](https://youtu.be/kl6NwWYxvbM?feature=shared), 텍스트에서 DSL로 변환하는 프로세스(DSL이 지정된 데이터베이스와 상호 작용하는 데 필요한 도메인 특정 언어)에 대한 [블로그 게시물 개요](https://blog.langchain.dev/query-construction/) 및 RAG from Scratch 비디오를 참조하세요. 이렇게 하면 사용자 질문이 구조화된 쿼리로 변환됩니다.

#### Indexing[​](https://python.langchain.com/v0.2/docs/concepts/#indexing "Direct link to Indexing")

Fourth, consider the design of your document index. A simple and powerful idea is to **decouple the documents that you index for retrieval from the documents that you pass to the LLM for generation.** Indexing frequently uses embedding models with vector stores, which [compress the semantic information in documents to fixed-size vectors](https://python.langchain.com/v0.2/docs/concepts/#embedding-models).

Many RAG approaches focus on splitting documents into chunks and retrieving some number based on similarity to an input question for the LLM. But chunk size and chunk number can be difficult to set and affect results if they do not provide full context for the LLM to answer a question. Furthermore, LLMs are increasingly capable of processing millions of tokens.

Two approaches can address this tension: (1) [Multi Vector](https://python.langchain.com/v0.2/docs/how_to/multi_vector/) retriever using an LLM to translate documents into any form (e.g., often into a summary) that is well-suited for indexing, but returns full documents to the LLM for generation. (2) [ParentDocument](https://python.langchain.com/v0.2/docs/how_to/parent_document_retriever/) retriever embeds document chunks, but also returns full documents. The idea is to get the best of both worlds: use concise representations (summaries or chunks) for retrieval, but use the full documents for answer generation.

|Name|Index Type|Uses an LLM|When to Use|Description|
|---|---|---|---|---|
|[Vector store](https://python.langchain.com/v0.2/docs/how_to/vectorstore_retriever/)|Vector store|No|If you are just getting started and looking for something quick and easy.|This is the simplest method and the one that is easiest to get started with. It involves creating embeddings for each piece of text.|
|[ParentDocument](https://python.langchain.com/v0.2/docs/how_to/parent_document_retriever/)|Vector store + Document Store|No|If your pages have lots of smaller pieces of distinct information that are best indexed by themselves, but best retrieved all together.|This involves indexing multiple chunks for each document. Then you find the chunks that are most similar in embedding space, but you retrieve the whole parent document and return that (rather than individual chunks).|
|[Multi Vector](https://python.langchain.com/v0.2/docs/how_to/multi_vector/)|Vector store + Document Store|Sometimes during indexing|If you are able to extract information from documents that you think is more relevant to index than the text itself.|This involves creating multiple vectors for each document. Each vector could be created in a myriad of ways - examples include summaries of the text and hypothetical questions.|
|[Time-Weighted Vector store](https://python.langchain.com/v0.2/docs/how_to/time_weighted_vectorstore/)|Vector store|No|If you have timestamps associated with your documents, and you want to retrieve the most recent ones|This fetches documents based on a combination of semantic similarity (as in normal vector retrieval) and recency (looking at timestamps of indexed documents)|

TIP

- See our RAG from Scratch video on [indexing fundamentals](https://youtu.be/bjb_EMsTDKI?feature=shared)
- See our RAG from Scratch video on [multi vector retriever](https://youtu.be/gTCU9I6QqCE?feature=shared)

Fifth, consider ways to improve the quality of your similarity search itself. Embedding models compress text into fixed-length (vector) representations that capture the semantic content of the document. This compression is useful for search / retrieval, but puts a heavy burden on that single vector representation to capture the semantic nuance / detail of the document. In some cases, irrelevant or redundant content can dilute the semantic usefulness of the embedding.

[ColBERT](https://docs.google.com/presentation/d/1IRhAdGjIevrrotdplHNcc4aXgIYyKamUKTWtB3m3aMU/edit?usp=sharing) is an interesting approach to address this with a higher granularity embeddings: (1) produce a contextually influenced embedding for each token in the document and query, (2) score similarity between each query token and all document tokens, (3) take the max, (4) do this for all query tokens, and (5) take the sum of the max scores (in step 3) for all query tokens to get a query-document similarity score; this token-wise scoring can yield strong results.

![](https://python.langchain.com/v0.2/assets/images/colbert-0bf5bd7485724d0005a2f5bdadbdaedb.png)

There are some additional tricks to improve the quality of your retrieval. Embeddings excel at capturing semantic information, but may struggle with keyword-based queries. Many [vector stores](https://python.langchain.com/v0.2/docs/integrations/retrievers/pinecone_hybrid_search/) offer built-in [hybrid-search](https://docs.pinecone.io/guides/data/understanding-hybrid-search) to combine keyword and semantic similarity, which marries the benefits of both approaches. Furthermore, many vector stores have [maximal marginal relevance](https://python.langchain.com/v0.1/docs/modules/model_io/prompts/example_selectors/mmr/), which attempts to diversify the results of a search to avoid returning similar and redundant documents.

|Name|When to use|Description|
|---|---|---|
|[ColBERT](https://python.langchain.com/v0.2/docs/integrations/providers/ragatouille/#using-colbert-as-a-reranker)|When higher granularity embeddings are needed.|ColBERT uses contextually influenced embeddings for each token in the document and query to get a granular query-document similarity score.|
|[Hybrid search](https://python.langchain.com/v0.2/docs/integrations/retrievers/pinecone_hybrid_search/)|When combining keyword-based and semantic similarity.|Hybrid search combines keyword and semantic similarity, marrying the benefits of both approaches.|
|[Maximal Marginal Relevance (MMR)](https://python.langchain.com/v0.2/docs/integrations/vectorstores/pinecone/#maximal-marginal-relevance-searches)|When needing to diversify search results.|MMR attempts to diversify the results of a search to avoid returning similar and redundant documents.|

TIP

See our RAG from Scratch video on [ColBERT](https://youtu.be/cN6S0Ehm7_8?feature=shared%3E).

#### Post-processing[​](https://python.langchain.com/v0.2/docs/concepts/#post-processing "Direct link to Post-processing")

Sixth, consider ways to filter or rank retrieved documents. This is very useful if you are [combining documents returned from multiple sources](https://python.langchain.com/v0.2/docs/integrations/retrievers/cohere-reranker/#doing-reranking-with-coherererank), since it can can down-rank less relevant documents and / or [compress similar documents](https://python.langchain.com/v0.2/docs/how_to/contextual_compression/#more-built-in-compressors-filters).

|Name|Index Type|Uses an LLM|When to Use|Description|
|---|---|---|---|---|
|[Contextual Compression](https://python.langchain.com/v0.2/docs/how_to/contextual_compression/)|Any|Sometimes|If you are finding that your retrieved documents contain too much irrelevant information and are distracting the LLM.|This puts a post-processing step on top of another retriever and extracts only the most relevant information from retrieved documents. This can be done with embeddings or an LLM.|
|[Ensemble](https://python.langchain.com/v0.2/docs/how_to/ensemble_retriever/)|Any|No|If you have multiple retrieval methods and want to try combining them.|This fetches documents from multiple retrievers and then combines them.|
|[Re-ranking](https://python.langchain.com/v0.2/docs/integrations/retrievers/cohere-reranker/)|Any|Yes|If you want to rank retrieved documents based upon relevance, especially if you want to combine results from multiple retrieval methods .|Given a query and a list of documents, Rerank indexes the documents from most to least semantically relevant to the query.|

TIP

여러 쿼리에 대한 사후 처리 접근 방식에 대한 [RAG-Fusion](https://youtu.be/77qELPbNgxA?feature=shared)의 RAG from Scratch 비디오를 참조하십시오. 여러 관점에서 사용자 질문을 다시 작성하고, 다시 작성된 각 질문에 대한 문서를 검색하고, 여러 검색 결과 목록의 순위를 결합하여 [RRF(Reciprocal Rank Fusion)](https://towardsdatascience.com/forget-rag-the-future-is-rag-fusion-1147298d8ad1)를 사용하여 단일 통합 순위를 생성합니다.

#### 세대[](https://python.langchain.com/v0.2/docs/concepts/#generation "Direct link to Generation")

**마지막으로, RAG 시스템에 자체 수정 기능을 구축하는 방법을 고려하십시오.** RAG 시스템은 낮은 품질의 검색(예: 사용자 질문이 인덱스의 도메인을 벗어난 경우) 및/또는 생성 시 환각으로 어려움을 겪을 수 있습니다. 순진한 검색-생성 파이프라인은 이러한 종류의 오류를 감지하거나 자체 수정할 수 있는 기능이 없습니다. ["흐름 공학"](https://x.com/karpathy/status/1748043513156272416)의 개념은 [코드 생성의 맥락에서](https://arxiv.org/abs/2401.08500) 도입되었습니다 : 오류를 확인하고 자체 수정하기 위해 단위 테스트를 통해 코드 질문에 대한 답변을 반복적으로 구축합니다. Self-RAG 및 Corrective-RAG와 같은 여러 작업에서이 RAG를 적용했습니다. 두 경우 모두에서, 문서 관련성, 환각 및/또는 답변 품질에 대한 검사는 RAG 답변 생성 플로우에서 수행된다.

우리는 그래프가 논리적 흐름을 안정적으로 표현할 수 있는 좋은 방법이라는 것을 발견했으며, 아래 그림과 같이 [LangGraph를 사용하여](https://github.com/langchain-ai/langgraph/tree/main/examples/rag) 이러한 논문 중 몇 가지의 아이디어를 구현했습니다(빨간색 - 라우팅, 파란색 - 폴백, 녹색 - 자체 수정).

- **라우팅:** 적응형 RAG([종이](https://arxiv.org/abs/2403.14403)). 위에서 논의한 대로 질문을 다른 검색 접근 방식으로 라우팅합니다.
- **대체:** 교정 RAG([종이](https://arxiv.org/pdf/2401.15884.pdf)). 문서가 쿼리와 관련이 없는 경우 웹 검색으로 대체Fallback to web search if docs are not relevant to query
- **자기 수정:** Self-RAG([종이](https://arxiv.org/abs/2310.11511)). 환각으로 답을 수정하거나 질문을 해결하지 마십시오.

![](https://python.langchain.com/v0.2/assets/images/langgraph_rag-f039b41ef268bf46783706e58726fd9c.png)

|이름|사용 시기|묘사|
|---|---|---|
|자체 RAG|환각이나 관련 없는 내용으로 답변을 수정해야 할 때.|Self-RAG는 RAG 응답 생성 흐름 중에 문서 관련성, 환각 및 응답 품질을 확인하여 반복적으로 답변을 작성하고 오류를 자체 수정합니다.|
|교정-RAG|관련성이 낮은 문서에 대한 대체 메커니즘이 필요한 경우.|Corrective-RAG에는 검색된 문서가 쿼리와 관련이 없는 경우 대체(예: 웹 검색)가 포함되어 있어 더 높은 품질과 더 관련성 있는 검색을 보장합니다.|

팁

LangGraph를 사용한 RAG를 보여주는 여러 비디오와 쿡북을 참조하십시오.

- [LangGraph 교정 RAG](https://www.youtube.com/watch?v=E2shqsYwxck)
- [Adaptive, Self-RAG 및 Corrective RAG를 결합한 LangGraph](https://www.youtube.com/watch?v=-ROS6gfYIts)
- [Cookbooks for RAG using LangGraph](https://github.com/langchain-ai/langgraph/tree/main/examples/rag)

See our LangGraph RAG recipes with partners:

- [Meta](https://github.com/meta-llama/llama-recipes/tree/main/recipes/3p_integrations/langchain)
- [Mistral](https://github.com/mistralai/cookbook/tree/main/third_party/langchain)

### Text splitting[​](https://python.langchain.com/v0.2/docs/concepts/#text-splitting "Direct link to Text splitting")

LangChain offers many different types of . These all live in the package.`text splitters``langchain-text-splitters`

Table columns:

- **Name**: Name of the text splitter
- **Classes**: Classes that implement this text splitter
- **Splits On**: How this text splitter splits text
- **Adds Metadata**: Whether or not this text splitter adds metadata about where each chunk came from.
- **Description**: Description of the splitter, including recommendation on when to use it.

|Name|Classes|Splits On|Adds Metadata|Description|
|---|---|---|---|---|
|Recursive|[RecursiveCharacterTextSplitter](https://python.langchain.com/v0.2/docs/how_to/recursive_text_splitter/), [RecursiveJsonSplitter](https://python.langchain.com/v0.2/docs/how_to/recursive_json_splitter/)|A list of user defined characters||Recursively splits text. This splitting is trying to keep related pieces of text next to each other. This is the to start splitting text.`recommended way`|
|HTML|[HTMLHeaderTextSplitter](https://python.langchain.com/v0.2/docs/how_to/HTML_header_metadata_splitter/), [HTMLSectionSplitter](https://python.langchain.com/v0.2/docs/how_to/HTML_section_aware_splitter/)|HTML specific characters|✅|Splits text based on HTML-specific characters. Notably, this adds in relevant information about where that chunk came from (based on the HTML)|
|Markdown|[MarkdownHeaderTextSplitter](https://python.langchain.com/v0.2/docs/how_to/markdown_header_metadata_splitter/),|Markdown specific characters|✅|Splits text based on Markdown-specific characters. Notably, this adds in relevant information about where that chunk came from (based on the Markdown)|
|Code|[many languages](https://python.langchain.com/v0.2/docs/how_to/code_splitter/)|Code (Python, JS) specific characters||Splits text based on characters specific to coding languages. 15 different languages are available to choose from.|
|Token|[many classes](https://python.langchain.com/v0.2/docs/how_to/split_by_token/)|Tokens||Splits text on tokens. There exist a few different ways to measure tokens.|
|Character|[CharacterTextSplitter](https://python.langchain.com/v0.2/docs/how_to/character_text_splitter/)|A user defined character||Splits text based on a user defined character. One of the simpler methods.|
|Semantic Chunker (Experimental)|[SemanticChunker](https://python.langchain.com/v0.2/docs/how_to/semantic-chunker/)|Sentences||First splits on sentences. Then combines ones next to each other if they are semantically similar enough. Taken from [Greg Kamradt](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb)|
|Integration: AI21 Semantic|[AI21SemanticTextSplitter](https://python.langchain.com/v0.2/docs/integrations/document_transformers/ai21_semantic_text_splitter/)||✅|Identifies distinct topics that form coherent pieces of text and splits along those.|

### Evaluation[​](https://python.langchain.com/v0.2/docs/concepts/#evaluation "Direct link to Evaluation")

Evaluation is the process of assessing the performance and effectiveness of your LLM-powered applications. It involves testing the model's responses against a set of predefined criteria or benchmarks to ensure it meets the desired quality standards and fulfills the intended purpose. This process is vital for building reliable applications.

![](https://python.langchain.com/v0.2/assets/images/langsmith_evaluate-7d48643f3e4c50d77234e13feb95144d.png)

[LangSmith](https://docs.smith.langchain.com/)는 다음과 같은 몇 가지 방법으로 이 프로세스를 지원합니다.

- 추적 및 주석 기능을 통해 데이터 세트를 더 쉽게 만들고 큐레이팅할 수 있습니다
- 메트릭을 정의하고 데이터 세트에 대해 앱을 실행하는 데 도움이 되는 평가 프레임워크를 제공합니다
- 이를 통해 시간 경과에 따른 결과를 추적하고 일정에 따라 또는 CI/코드의 일부로 평가자를 자동으로 실행할 수 있습니다

자세한 내용은 [이 LangSmith 가이드를](https://docs.smith.langchain.com/concepts/evaluation) 확인하세요.

### 추적[](https://python.langchain.com/v0.2/docs/concepts/#tracing "Direct link to Tracing")

추적은 기본적으로 응용 프로그램이 입력에서 출력으로 이동하기 위해 수행하는 일련의 단계입니다. 추적에는 라는 개별 단계가 포함되어 있습니다. 이는 모델, 리트리버, 도구 또는 하위 체인. 추적은 체인과 에이전트 내부를 관찰할 수 있는 기능을 제공하며 문제를 진단하는 데 매우 중요합니다.`runs`

더 자세한 내용은 [이 LangSmith 개념 가이드를](https://docs.smith.langchain.com/concepts/tracing) 확인하세요.